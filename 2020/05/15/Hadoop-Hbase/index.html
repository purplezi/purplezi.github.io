<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="lazy x 2">
  <meta name="author" content="Purplezi">
  <meta name="keywords" content="">
  <title>NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用 - Purplezi</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/Monokai%20Sublime.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Purplezi</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">Categories</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  Friday, May 15th 2020, 5:32 pm
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    4.1k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      17 分钟
                  </span>
                

                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
            <div class="markdown-body">
              <style>
  /* 设置整个页面的字体 */
  html, body, .markdown-body {
    font-family: Georgia, sans, serif;
    font-size: 15px;
  }

  /* 只设置 markdown 字体 */
  .markdown-body {
    font-family: Georgia, sans, serif;
    font-size: 20px;
  }
</style>
<ul>
<li>Hbase是一种NoSQL数据库，这意味着它不像传统的RDBMS(关系数据库管理系统 Relational Database Management System)数据库那样支持SQL作为查询语言</li>
<li>Hbase是一种分布式存储的数据库，技术上来讲，它更像是分布式存储而不是分布式数据库</li>
<li>数据库量要足够多，如果有十亿及百亿行数据，那么Hbase是一个很好的选项，如果只有几百万行甚至不到的数据量，RDBMS是一个很好的选择。因为数据量小的话，真正能工作的机器量少，剩余的机器都处于空闲的状态</li>
<li>保证硬件资源足够，每个HDFS集群在少于5个节点的时候，都不能表现的很好。因为HDFS默认的复制数量是3，再加上一个NameNode</li>
</ul>
<a id="more"></a>
<h2 id="实验环境">实验环境</h2>
<ul>
<li>VMware Workstation Pro 12</li>
<li>系统为Ubuntu 16.04 Server的Linux虚拟机</li>
<li><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">jdk-8u201-linux-x64.tar.gz</a>，<a href="https://www.oracle.com/webfolder/s/digest/8u201checksum.html" target="_blank" rel="noopener">校验和</a></li>
<li><a href="http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">hadoop-3.1.2.tar.gz</a>，<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz.mds" target="_blank" rel="noopener">校验和</a></li>
<li>hbase-1.2.11-bin.tar.gz，<a href="https://archive.apache.org/dist/hbase/hbase-1.2.11/hbase-1.2.11-bin.tar.gz.sha512" target="_blank" rel="noopener">校验和</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">官方教程1</a>、<a href="https://hbase.apache.org/book.html" target="_blank" rel="noopener">官方教程2</a></li>
</ul>
<h2 id="hbase结构">HBase结构</h2>
<p><img src="hbase-construction.webp" srcset="/img/loading.gif"></p>
<h2 id="实验过程">实验过程</h2>
<h3 id="准备阶段">准备阶段</h3>
<h4 id="创建实验用户hadoop">创建实验用户hadoop</h4>
<ul>
<li><p>[再已配置mysql cluster的基础上] 可以采用已有的mysql用户，给mysql用户做相应管理员权限赋权，后续需要用到用户名hadoop的时候，使用mysql</p></li>
<li><p>此处选择新创建hadoop用户</p>
<pre><code>$ sudo useradd -m hadoop -s /bin/bash  #创建hadoop用户，并使用/bin/bash作为shell
$ sudo passwd hadoop  #为hadoop用户设置密码，之后需要连续输入两次密码
$ sudo adduser hadoop sudo #为hadoop用户增加管理员权限
$ su - hadoop            #切换当前用户为用户hadoop
$ sudo apt-get update    #更新hadoop用户的apt,方便后面的安装</code></pre>
<p><img src="adduserhadoop.png" srcset="/img/loading.gif"></p></li>
</ul>
<h4 id="ssh配置免密登录">SSH配置免密登录</h4>
<ul>
<li><p>安装SSH，设置SSH无密码登陆</p>
<pre><code>$ sudo apt-get install openssh-server   #安装SSH server
$ ssh localhost         #登陆SSH，第一次登陆输入yes
$ exit                  #退出登录的ssh localhost</code></pre>
<p><img src="ssh-install.png" srcset="/img/loading.gif" width=70%></p></li>
<li><p>生成密钥</p>
<pre><code>$ cd ~/.ssh/                            #如果没法进入该目录，执行一次ssh localhost
$ ssh-keygen -t rsa　　
# 需要连续敲击三次回车
# 第一次回车是让KEY存于默认位置，以方便后续的命令输入
# 第二次和第三次是确定passphrase，相关性不大</code></pre>
<p><img src="ssh-keygen.png" srcset="/img/loading.gif" width=70%></p></li>
<li><p>加入授权，免密登录</p>
<pre><code>$ cat ./id_rsa.pub &gt;&gt; ./authorized_keys  #加入授权
$ ssh localhost  #此时已不需密码即可登录localhost</code></pre>
<p><img src="ssh-authorizedkeys.png" srcset="/img/loading.gif" width=70%></p></li>
</ul>
<h3 id="安装jdk1.8">安装jdk1.8</h3>
<ul>
<li><p>在<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">oracle官网</a>下载jdk1.8，根据个人电脑系统选择对应版本，如<code>jdk-8u201-linux-x64.tar.gz</code></p></li>
<li><p>安装过程</p>
<pre><code>$ mkdir /usr/lib/jvm  #创建jvm文件夹
$ sudo tar zxvf  jdk-8u201-linux-x64.tar.gz  -C /usr/lib/jvm  #/ 解压到/usr/lib/jvm目录下
$ cd /usr/lib/jvm  #进入该目录
$ mv  jdk1.8.0_201 java  #重命名为java
$ vi ~/.bashrc  #给JDK配置环境变量</code></pre></li>
<li><p>编辑环境变量<code>vi ~/.bashrc</code>，在<code>.bashrc</code>文件添加如下指令：</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/java
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATH
export PATH=${JAVA_HOME}/bin:$PATH</code></pre>
<p><img src="javaenrpath.png" srcset="/img/loading.gif"></p></li>
<li><p>使得环境变量生效，并查看是否安装成功</p>
<pre><code>$ source ~/.bashrc  #使新配置的环境变量生效
$ java -version  #检测是否安装成功，查看java版本</code></pre>
<p><img src="javainstallsuccess.png" srcset="/img/loading.gif"></p></li>
</ul>
<h3 id="安装hadoop-3.1.2">安装hadoop-3.1.2</h3>
<ul>
<li><p>下载<a href="http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">hadoop-3.1.2.tar.gz</a>并安装</p>
<pre><code>$ sudo tar -zxvf  hadoop-3.1.2.tar.gz  -C  /usr/local  #解压到/usr/local目录下
$ cd /usr/local
$ sudo mv  hadoop-3.1.2 hadoop  #重命名为hadoop
$ sudo chown -R hadoop ./hadoop  #修改文件权限，根据实际情况确定用户名</code></pre></li>
<li><p>配置环境变量，将下面代码添加到<code>.bashrc</code>文件:</p>
<pre><code>export HADOOP_HOME=/usr/local/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></pre></li>
<li><p>执行<code>source ~/.bashrc</code>使设置生效，并查看<code>hadoop</code>是否安装成功 <img src="hadoopinstallsuccess.png" srcset="/img/loading.gif"></p></li>
</ul>
<h3 id="伪分布配置">伪分布配置</h3>
<ul>
<li><code>Hadoop</code>可以在单节点上以伪分布式的方式运行，<code>Hadoop</code>进程以分离的<code>Java</code>进程来运行，节点既作为<code>NameNode</code>也作为 <code>DataNode</code>，同时，读取的是<code>HDFS</code>中的文件</li>
<li><code>Hadoop</code>的配置文件位于<code>/usr/local/hadoop/etc/hadoop/</code>中，伪分布式需要修改2个配置文件<code>core-site.xml</code>和<code>hdfs-site.xml</code></li>
<li><code>Hadoop</code>的配置文件是<code>xml</code>格式，每个配置以声明<code>property</code> 的<code>name</code>和<code>value</code>的方式来实现</li>
</ul>
<h4 id="修改hadoop-env.sh文件">修改hadoop-env.sh文件</h4>
<ul>
<li><p>首先将jdk1.8的路径添(<code>export JAVA_HOME=/usr/lib/jvm/java</code>)加到<code>hadoop-env.sh</code>文件，路径为<code>cd /usr/local/hadoop/etc/hadoop/</code></p>
<p><img src="hadoopenv.png" srcset="/img/loading.gif" width=70%></p></li>
</ul>
<h4 id="修改core-site.xml文件">修改core-site.xml文件</h4>
<div class="sourceCode" id="cb10"><pre class="sourceCode xml"><code class="sourceCode xml"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">&lt;configuration&gt;</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>          <span class="kw">&lt;property&gt;</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>             <span class="kw">&lt;name&gt;</span>hadoop.tmp.dir<span class="kw">&lt;/name&gt;</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>             <span class="kw">&lt;value&gt;</span>file:/usr/local/hadoop/tmp<span class="kw">&lt;/value&gt;</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>             <span class="kw">&lt;description&gt;</span>Abase for other temporary directories.<span class="kw">&lt;/description&gt;</span></span>
<span id="cb10-6"><a href="#cb10-6"></a>        <span class="kw">&lt;/property&gt;</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>        <span class="kw">&lt;property&gt;</span></span>
<span id="cb10-8"><a href="#cb10-8"></a>             <span class="kw">&lt;name&gt;</span>fs.defaultFS<span class="kw">&lt;/name&gt;</span></span>
<span id="cb10-9"><a href="#cb10-9"></a>             <span class="kw">&lt;value&gt;</span>hdfs://localhost:9000<span class="kw">&lt;/value&gt;</span></span>
<span id="cb10-10"><a href="#cb10-10"></a>        <span class="kw">&lt;/property&gt;</span></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="kw">&lt;/configuration&gt;</span></span></code></pre></div>
<p><img src="core-site.png" srcset="/img/loading.gif"></p>
<h4 id="配置hdfs-site.xml文件">配置hdfs-site.xml文件</h4>
<div class="sourceCode" id="cb11"><pre class="sourceCode xml"><code class="sourceCode xml"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">&lt;configuration&gt;</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>        <span class="kw">&lt;property&gt;</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>             <span class="kw">&lt;name&gt;</span>dfs.replication<span class="kw">&lt;/name&gt;</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>             <span class="kw">&lt;value&gt;</span>1<span class="kw">&lt;/value&gt;</span></span>
<span id="cb11-5"><a href="#cb11-5"></a>        <span class="kw">&lt;/property&gt;</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>        <span class="kw">&lt;property&gt;</span></span>
<span id="cb11-7"><a href="#cb11-7"></a>             <span class="kw">&lt;name&gt;</span>dfs.namenode.name.dir<span class="kw">&lt;/name&gt;</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>             <span class="kw">&lt;value&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="kw">&lt;/value&gt;</span></span>
<span id="cb11-9"><a href="#cb11-9"></a>        <span class="kw">&lt;/property&gt;</span></span>
<span id="cb11-10"><a href="#cb11-10"></a>        <span class="kw">&lt;property&gt;</span></span>
<span id="cb11-11"><a href="#cb11-11"></a>             <span class="kw">&lt;name&gt;</span>dfs.datanode.data.dir<span class="kw">&lt;/name&gt;</span></span>
<span id="cb11-12"><a href="#cb11-12"></a>             <span class="kw">&lt;value&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="kw">&lt;/value&gt;</span></span>
<span id="cb11-13"><a href="#cb11-13"></a>        <span class="kw">&lt;/property&gt;</span></span>
<span id="cb11-14"><a href="#cb11-14"></a><span class="kw">&lt;/configuration&gt;</span></span></code></pre></div>
<p><img src="hdfs-site.png" srcset="/img/loading.gif"></p>
<ul>
<li><p><code>Hadoop</code>配置文件参数</p>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 46%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="header">
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>fs.defaultFS</td>
<td>NameNode URI The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem.</td>
<td>hdfs://host:port/</td>
</tr>
<tr class="even">
<td>dfs.namenode.name.dir</td>
<td>Determines where on the local filesystem the DFS name node should store the name table(fsimage) 在本地文件系统所在的NameNode的存储空间和持续化处理日志</td>
<td>如果这是一个以逗号分隔的目录列表，然后将名称表被复制的所有目录，以备不时需</td>
</tr>
<tr class="odd">
<td>dfs.datanode.data.dir</td>
<td>Determines where on the local filesystem an DFS data node should store its blocks 逗号分隔的一个DataNode上，它应该保存它的块的本地文件系统的路径列表</td>
<td>如果这是一个以逗号分隔的目录列表，那么数据将被存储在所有命名的目录，通常在不同的设备</td>
</tr>
</tbody>
</table></li>
<li><p><code>Hadoop</code>的运行方式是由配置文件决定的(运行<code>Hadoop</code>时会读取配置文件)</p></li>
<li><p>因此如果需要从伪分布式模式切换回非分布式模式，需要删除 <code>core-site.xml</code>中的配置项</p></li>
<li><p>伪分布式虽然只需要配置<code>fs.defaultFS</code>和<code>dfs.replication</code>就可以运行（可参考官方教程）</p></li>
<li><p>若没有配置<code>hadoop.tmp.dir</code>参数，则默认使用的临时目录为 <code>/tmp/hadoo-hadoop</code>，而这个目录在重启时有可能被系统清理掉，导致必须重新执行<code>format</code>。所以同时也指定<code>dfs.namenode.name.dir</code>和<code>dfs.datanode.data.dir</code>，否则在接下来的步骤中可能会出错。</p></li>
<li><p>配置完成后，执行 NameNode 的格式化</p>
<pre><code>cd /usr/local/hadoop/
./bin/hdfs namenode –format</code></pre>
<p><img src="namenode-format.png" srcset="/img/loading.gif"></p>
<p><img src="format-success.png" srcset="/img/loading.gif"></p></li>
<li><p>启动<code>namenode</code>和<code>datanode</code>进程，并查看启动结果</p>
<pre><code>$ ./sbin/start-dfs.sh
$ jps</code></pre>
<ul>
<li>启动完成后，可以通过命令<code>jps</code>来判断是否成功启动，若成功启动则会列出如下进程: <code>NameNode</code>、<code>DataNode</code> 和 <code>SecondaryNameNode</code> <img src="start-namenode-datanode.png" srcset="/img/loading.gif"></li>
</ul></li>
<li><p>Hadoop出现错误：<code>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code>，解决方案是在文件<code>hadoop-env.sh</code>中增加：<code>export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"</code></p>
<p><img src="hadoop-warn.png" srcset="/img/loading.gif"></p></li>
<li><p>出现<code>ssh: connect to host master port 22: Connection timed out</code></p>
<p><img src="hdfs-ssh-timeout.png" srcset="/img/loading.gif"></p>
<ul>
<li><a href="https://www.itread01.com/content/1548390616.html" target="_blank" rel="noopener">解决方法：</a>
<ul>
<li><p>查看防火墙</p></li>
<li><p>查看ssh是否开启，22端口是否监听</p></li>
<li><p><code>sudo vi /etc/hosts</code></p>
<p><img src="etc-host.png" srcset="/img/loading.gif"></p>
<ul>
<li>127.0.0.1和127.0.1.1都是本地回路/回环地址（区别搜索）</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>有可能出现要求输入localhost密码的情况，如果此时明明输入的是正确的密码却仍无法登入，其原因是由于如果不输入用户名的时候默认的是root用户，但是ssh服务默认没有开root用户的ssh权限</p>
<ul>
<li>输入指令：<code>$vim /etc/ssh/sshd_config</code></li>
<li>PermitRootLogin yes</li>
<li>之后输入下列代码重启SSH服务：<code>$ /etc/init.d/sshd restart</code>，即可正常登入（免密码登录参考前文）</li>
<li>注：Ubuntu 16.04若安装openssh-server，是无法找到/etc/init.d/sshd文件的，但是可以启动/etc/init.d/ssh</li>
</ul></li>
<li><p><a href="https://blog.csdn.net/sinat_19628145/article/details/56494337" target="_blank" rel="noopener">secondarynamenode没有启动</a></p></li>
<li><p><a href="https://blog.csdn.net/weixin_38750084/article/details/82856211" target="_blank" rel="noopener">NameNode和SecondaryNameNode的区别</a></p></li>
</ul>
<h4 id="访问web界面">访问web界面</h4>
<ul>
<li><p>成功启动后，如果是在桌面版linux上安装的，也可以访问 Web 界面 http://localhost:9870（老版本为50070） 查看NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</p></li>
<li><p>如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost）</p></li>
<li><p>此处配置了静态ip地址为<code>192.18.50.129</code>，在宿主机上输入<code>http://192.168.50.129:9870</code></p>
<p><img src="hadoopweb.png" srcset="/img/loading.gif"></p></li>
</ul>
<h4 id="注意">注意</h4>
<ul>
<li>DFS文件系统格式化时，会在namenode数据文件夹（即配置文件中dfs.namenode.name.dir在本地系统的路径）中保存一个current/VERSION文件，记录clusterID，标识了所格式化的 namenode的版本</li>
<li>如果频繁的格式化namenode，那么datanode中保存（即配置文件中dfs.data.dir在本地系统的路径）的current/VERSION文件只是你第一次格式化时保存的namenode的ID，因此就会造成datanode与namenode之间的 id 不一致。可能导致datanode无法启动</li>
</ul>
<h4 id="例子">例子</h4>
<ul>
<li><p>创建执行MapReduce作业所需的 DFS 目录:</p>
<pre><code>$ bin/hdfs dfs -mkdir /user
$ bin/hdfs dfs -mkdir /user/&lt;username&gt;  #&lt;username&gt; 问用户名，如hadoop</code></pre></li>
<li><p>拷贝输入文件到分布式文件系统:</p>
<pre><code>$ bin/hdfs dfs -put etc/hadoop input</code></pre></li>
<li><p>运行一些例子</p>
<pre><code>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#39;dfs[a-z.]+&#39;</code></pre></li>
<li><p>查看输出的文件(files): 从分布式文件系统中拷贝文件到本地文件系统并查看:</p>
<pre><code>bin/hdfs dfs -get output output
cat output/*</code></pre>
<p>或者直接在分布式文件系统上查看:</p>
<p><code>$ bin/hdfs dfs -cat output/*</code></p>
<p>我也不知道对不对</p>
<p><img src="mapreduce-output.png" srcset="/img/loading.gif"></p></li>
<li><p>结束运行<code>sbin/stop-dfs.sh</code></p></li>
</ul>
<h4 id="yarn单机配置">YARN单机配置</h4>
<ul>
<li><p>通过设置几个参数并运行ResourceManager daemon and NodeManager daemon，可以在YARN上以伪分布模式运行MapReduce job</p>
<p>配置mapred-site.xml(cd /usr/local/hadoop/etc/hadoop)如下:</p>
<p><img src="mapred-site.png" srcset="/img/loading.gif"></p>
<p>配置yarn-site.xml如下：</p>
<p><img src="yarn-site.png" srcset="/img/loading.gif"></p></li>
<li><p>启动ResourceManager daemon 和 NodeManager daemon:</p>
<pre><code>cd /usr/local/hadoop
sbin/start-yarn.sh

# 输出如下
Starting resourcemanager
Starting nodemanagers

sbin/stop-yarn.sh # 关闭</code></pre></li>
<li><p>如果是在桌面版linux上安装的, 可以用浏览器打开资源管理器端口，默认为：ResourceManager - http://localhost:8088/ （如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost） - 同上 <img src="start-yarn.png" srcset="/img/loading.gif"></p></li>
</ul>
<h3 id="安装hbase和简单使用">安装Hbase和简单使用</h3>
<h4 id="安装">安装</h4>
<pre><code># 解压安装包hbase-1.2.11-bin.tar.gz至路径 /usr/local
$ sudo tar -zxvf  hbase-1.2.11-bin.tar.gz -C /usr/local
# 将解压的文件名hbase-1.2.11改为hbase，以方便使用
$ sudo mv /usr/local/hbase-1.2.11  /usr/local/hbase
cd /usr/local
$ sudo chown -R hadoop ./hbase  # 将hbase下的所有文件的所有者改为hadoop，hadoop是当前用户的用户名。</code></pre>
<h4 id="配置环境变量">配置环境变量</h4>
<ul>
<li><p>给hbase配置环境变量，将下面代码添加到.bashrc文件<code>:export PATH=$PATH:/usr/local/hbase</code></p>
<p><img src="hbase-env.png" srcset="/img/loading.gif"></p></li>
<li><p>执行source ~/.bashrc使设置生效，并查看hbase是否安装成功<code>/usr/local/hbase/bin/hbase version</code>或者直接<code>hbase -version</code></p>
<p><img src="hbase-success.png" srcset="/img/loading.gif"></p></li>
</ul>
<h4 id="hbase单机配置">hBase单机配置</h4>
<ul>
<li><p>单机配置（可能需要配置JAVA_HOME环境变量，由于本实验指南在HADOOP安装时已配置，故省略）</p></li>
<li><p>配置<code>/usr/local/hbase/conf/hbase-site.xml</code>如下</p>
<p><img src="hbase-site.png" srcset="/img/loading.gif"></p></li>
<li><p>采用如下命令启动服务、查看进程和启动客户端 <code>$ cd /usr/local/hbase     $ bin/start-hbase.sh     $ jps     $ bin/hbase shell</code></p>
<p><img src="hbase-start.png" srcset="/img/loading.gif"></p></li>
</ul>
<h4 id="配置伪分布模式的指南">配置伪分布模式的指南</h4>
<ul>
<li>配置分布模式方法请查阅官方文档</li>
</ul>
<h5 id="配置hbase-env.sh">配置hbase-env.sh</h5>
<ul>
<li><p><code>cd /usr/local/hbase/conf</code>修改<code>hbase-site.xml</code>文件</p>
<p><img src="modify-hbase-site.png" srcset="/img/loading.gif"></p>
<p>将HBase的数据存储到之前的Hadoop的HDFS上，hbase.rootdir的值便是HDFS上HBase数据存储的位置，值中的主机名和端口号要和之前Hadoop的core-site.xml中的fs.default.name的值相同</p></li>
<li><p>启动hBase <code># 先stop-hbase.sh     $ start-dfs.sh     $ cd /usr/local/hbase/bin     $ ./start-hbase.sh</code></p></li>
<li><p>hbase集群在启动的时候报错：JAVA_HOME is not set and Java could not be found出现这种错误，一般应该是hbase下conf文件下的hbase-env.sh文件中的java_home的环境变量没有配置或者是被注释了</p>
<p><img src="java_homeisnotset.png" srcset="/img/loading.gif"></p>
<p>解决方法：</p>
<pre><code>cd /usr/local/hbase/conf
vi hbase-env.sh
export JAVA_HOME=/usr/lib/jvm/java</code></pre>
<p><img src="java_home.png" srcset="/img/loading.gif"></p></li>
<li><p>正确顺序：启动Hadoop—&gt;启动HBase—&gt;关闭HBase—&gt;关闭Hadoop</p></li>
<li><p>注：执行jps命令，如果在Hadoop进程的基础上新增加了如下三个进程则表示HBase启动成功：1. HMaster，2. HRegionServer，3. HQuorumpeer</p></li>
</ul>
<h5 id="查看dfs中hbase-目录自动创建">查看DFS中Hbase 目录，自动创建</h5>
<pre><code>cd ~
hdfs dfs -ls /hbase</code></pre>
<blockquote>
<p>hadoop@zizi:~$ hdfs dfs -ls /hbase ls: Call From zizi/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused 该问题一般由于没有start dfs 和 yarn造成的</p>
</blockquote>
<p><img src="hdfs-dfs.png" srcset="/img/loading.gif"></p>
<ul>
<li><p>仅仅为了测试和学习，生产环境不会在一台机器上启动备份master</p></li>
<li><p>HMaster服务器控制HBase集群，图中的指令启动三个<strong>备份</strong>HMaster，体现了<strong>伪分布式</strong>(在一个机器上多个备份HMaster服务器)，一个HMaster没了，其他的还可以使用</p>
<p><img src="master-backup-start.png" srcset="/img/loading.gif"></p>
<pre><code>The HMaster server controls the HBase cluster. You can start up to 9 backup HMaster servers, which makes 10 total HMasters, counting the primary. 
To start a backup HMaster, use the local-master-backup.sh. 
For each backup master you want to start, add a parameter representing the port offset for that master. 
Each HMaster uses two ports (16000 and 16010 by default). 
The port offset is added to these ports, so using an offset of 2, the backup HMaster would use ports 16002 and 16012. 
The following command starts 3 backup servers using ports 16002/16012, 16003/16013, and 16005/16015.</code></pre></li>
<li><p>如：start 1 <img src="master-backup-1.png" srcset="/img/loading.gif"></p></li>
<li><p>http://192.168.50.129:16010/master-status可以访问，port=16000无法访问，port=16011可以访问</p>
<p><img src="master-status1.png" srcset="/img/loading.gif"></p></li>
<li><p>启动和停止附加区域服务器RegionServers</p>
<p><img src="regionalserver.png" srcset="/img/loading.gif"></p></li>
<li><p>关闭刚才开启的备份HMaster服务：<code>local-master-backup.sh stop 1</code></p></li>
</ul>
<h5 id="建表">建表</h5>
<ul>
<li><p>进入交互界面<code>$ hbase shell</code></p>
<p><img src="hbase-shell.png" srcset="/img/loading.gif"></p></li>
<li><p>使用create命令创建一个新表，必须规定表名和列族名</p>
<p>使用list 命令可以显示表信息</p>
<p>使用 describe 命令显示表的详细信息，此时表中的VERSIONS默认设置为1</p>
<p><img src="create-list-describe.png" srcset="/img/loading.gif"></p></li>
<li><p>向表中加入数据，使用 put 命令</p>
<p>使用scan命令扫描整个表取得数据</p>
<p>取一行数据，使用get指令</p>
<p><img src="put-scan-get.png" srcset="/img/loading.gif"></p></li>
<li><p>修改表模式，使用alter命令，如修改存储版本数，为5个版本</p>
<p><img src="alter-version.png" srcset="/img/loading.gif"></p></li>
</ul>
<h2 id="实验总结">实验总结</h2>
<ol type="1">
<li><p>请问伪分布和分布式的含义有何不同？就本实验，你是如何理解在一台计算机上做到“伪分布”的？</p>
<ul>
<li>伪分布式模式是一个相对简单的分布式模式，用来测试</li>
<li>不能把这个模式用于生产环节，也不能用于测试性能。</li>
<li>多个HMaster备份节点在一台机器上工作</li>
</ul></li>
<li><p>在1.2小节进行安装SSH并设置SSH无密码登陆，请问这个安装的目的是什么？ &gt; ssh must be installed and sshd must be running to use the Hadoop scripts that manage remote Hadoop daemons if the optional start and stop scripts are to be used. Additionally, it is recommmended that pdsh also be installed for better ssh resource management.</p>
<ul>
<li>ssh必须安装，sshd必须运行，Hadoop的脚本才可以远程操控其他的Hadoop和HBase进程</li>
<li>ssh之间必须都打通，远程登录、自动登录、免密登录</li>
</ul></li>
<li><p>如果继续向Hbase的test表中put行键为”row1”，值为其它字符串的数据，put 'test' ,'row1', 'cf:a', 'value6'，会发生什么？如果采用语句get 'test', 'row1', {COLUMN=&gt;'cf:a', VERSIONS=&gt;3} 进行查询，分析你得到的结果。put与关系数据库的插入有何不同？</p>
<p><img src="put.png" srcset="/img/loading.gif"></p>
<ul>
<li>VERSIONS的作用
<ul>
<li>当想要用HBase存储历史几个版本的数据是（达到类似于git的效果时）可以设定版本号，版本号为几就是存储几个版本的数据</li>
<li>最开始，没有设定VERSION，则为VERSIONS为1，也就是说，默认情况只会存取一个版本的列数据，当再次插入的时候，后面的值会覆盖前面的值</li>
<li>后面修改表结构，让Hbase表支持存储5个VERSIONS的版本列数据 alter 'test', NAME=&gt;'cf',VERSIONS=&gt;5</li>
<li>解析：一开始row1只有一条数据，然后又插入了第二条数据，虽然scan 'test'只返回最新的数据，但是用get那条语句能够返回历史版本，所以返回两条数据 <img src="versions.png" srcset="/img/loading.gif"></li>
</ul></li>
</ul></li>
</ol>
<h2 id="错误与解决">错误与解决</h2>
<ul>
<li>如何执行shell脚本！！！-牢记 <code>hadoop@zizi:/usr/local/hbase/bin$ local-master-backup.sh start 2 3 5     local-master-backup.sh: command not found</code></li>
<li><a href="https://blog.csdn.net/tiankong_12345/article/details/93585463" target="_blank" rel="noopener">Hbase启动警告：Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m;</a></li>
<li>hBase中get和scan的区别和总结</li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://www.jianshu.com/p/6aeceb5d49cf" target="_blank" rel="noopener">HBase入门精要-百闻不如一Run</a></li>
<li><a href="https://www.jianshu.com/p/b23800d9b227" target="_blank" rel="noopener">入门HBase，看这一篇就够了</a></li>
</ul>

            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/DataBase/">DataBase</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
                  <span>
                <i class="iconfont icon-tag"></i>
                    
                      <a class="hover-with-bg" href="/tags/Hadoop/">Hadoop</a>
                    
                      <a class="hover-with-bg" href="/tags/Hbase/">Hbase</a>
                    
                  </span>
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var post = $('#post');
      var toc = $('#toc');
      var tocLimMax = post.offset().top + post.height() - navHeight;

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = $('#board-ctn').css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>










<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  ');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>



  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });

      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script  src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  










</body>
</html>
