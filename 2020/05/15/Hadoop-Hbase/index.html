<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用 - Purplezi</title><meta description="&amp;#x2F;* 设置整个页面的字体 *&amp;#x2F;   html, body, .markdown-body {     font-family: Georgia, sans, serif;     font-size: 15px;   }    &amp;#x2F;* 只设置 markdown 字体 *&amp;#x2F;   .markdown-body {     font-family: Georgia, sans, s"><meta property="og:type" content="blog"><meta property="og:title" content="NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用"><meta property="og:url" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/"><meta property="og:site_name" content="Purplezi"><meta property="og:description" content="&amp;#x2F;* 设置整个页面的字体 *&amp;#x2F;   html, body, .markdown-body {     font-family: Georgia, sans, serif;     font-size: 15px;   }    &amp;#x2F;* 只设置 markdown 字体 *&amp;#x2F;   .markdown-body {     font-family: Georgia, sans, s"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-construction.webp"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/adduserhadoop.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-install.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-keygen.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-authorizedkeys.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/javaenrpath.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/javainstallsuccess.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopinstallsuccess.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopenv.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/core-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/namenode-format.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/format-success.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/start-namenode-datanode.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoop-warn.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-ssh-timeout.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/etc-host.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopweb.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/mapreduce-output.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/mapred-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/yarn-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/start-yarn.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-env.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-success.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-start.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/modify-hbase-site.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/java_homeisnotset.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/java_home.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-dfs.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-backup-start.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-backup-1.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-status1.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/regionalserver.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-shell.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/create-list-describe.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/put-scan-get.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/alter-version.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/put.png"><meta property="og:image" content="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/versions.png"><meta property="article:published_time" content="2020-05-15T09:32:27.000Z"><meta property="article:modified_time" content="2020-06-11T05:31:52.725Z"><meta property="article:author" content="Purplezi"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="Hbase"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="hbase-construction.webp"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/"},"headline":"Purplezi","image":["https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/adduserhadoop.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-install.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-keygen.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/ssh-authorizedkeys.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/javaenrpath.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/javainstallsuccess.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopinstallsuccess.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopenv.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/core-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/namenode-format.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/format-success.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/start-namenode-datanode.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoop-warn.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-ssh-timeout.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/etc-host.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hadoopweb.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/mapreduce-output.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/mapred-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/yarn-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/start-yarn.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-env.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-success.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-start.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/modify-hbase-site.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/java_homeisnotset.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/java_home.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hdfs-dfs.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-backup-start.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-backup-1.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/master-status1.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/regionalserver.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/hbase-shell.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/create-list-describe.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/put-scan-get.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/alter-version.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/put.png","https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/versions.png"],"datePublished":"2020-05-15T09:32:27.000Z","dateModified":"2020-06-11T05:31:52.725Z","author":{"@type":"Person","name":"Purplezi"},"description":"&#x2F;* 设置整个页面的字体 *&#x2F;\r   html, body, .markdown-body {\r     font-family: Georgia, sans, serif;\r     font-size: 15px;\r   }\r \r   &#x2F;* 只设置 markdown 字体 *&#x2F;\r   .markdown-body {\r     font-family: Georgia, sans, s"}</script><link rel="canonical" href="https://purplezi.gitee.io/2020/05/15/Hadoop-Hbase/"><link rel="icon" href="/img/fish-tank.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai-sublime.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/plant-pot.svg" alt="Purplezi" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/photos">Photos</a><a class="navbar-item" href="/books">Books</a><a class="navbar-item" href="/movies">Movies</a><a class="navbar-item" href="/games">Games</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/purplezi"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-15T09:32:27.000Z" title="2020-05-15T09:32:27.000Z">2020-05-15</time><span class="level-item"><a class="link-muted" href="/categories/DataBase/">DataBase</a></span><span class="level-item">29 minutes read (About 4284 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用</h1><div class="content"><style>
  /* 设置整个页面的字体 */
  html, body, .markdown-body {
    font-family: Georgia, sans, serif;
    font-size: 15px;
  }

  /* 只设置 markdown 字体 */
  .markdown-body {
    font-family: Georgia, sans, serif;
    font-size: 15px;
  }
</style>
<ul>
<li>Hbase是一种NoSQL数据库，这意味着它不像传统的RDBMS(关系数据库管理系统 Relational Database Management System)数据库那样支持SQL作为查询语言</li>
<li>Hbase是一种分布式存储的数据库，技术上来讲，它更像是分布式存储而不是分布式数据库</li>
<li>数据库量要足够多，如果有十亿及百亿行数据，那么Hbase是一个很好的选项，如果只有几百万行甚至不到的数据量，RDBMS是一个很好的选择。因为数据量小的话，真正能工作的机器量少，剩余的机器都处于空闲的状态</li>
<li>保证硬件资源足够，每个HDFS集群在少于5个节点的时候，都不能表现的很好。因为HDFS默认的复制数量是3，再加上一个NameNode</li>
</ul>
<a id="more"></a>
<h2 id="实验环境">实验环境</h2>
<ul>
<li>VMware Workstation Pro 12</li>
<li>系统为Ubuntu 16.04 Server的Linux虚拟机</li>
<li><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">jdk-8u201-linux-x64.tar.gz</a>，<a href="https://www.oracle.com/webfolder/s/digest/8u201checksum.html">校验和</a></li>
<li><a href="http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz">hadoop-3.1.2.tar.gz</a>，<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz.mds">校验和</a></li>
<li>hbase-1.2.11-bin.tar.gz，<a href="https://archive.apache.org/dist/hbase/hbase-1.2.11/hbase-1.2.11-bin.tar.gz.sha512">校验和</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/SingleCluster.html">官方教程1</a>、<a href="https://hbase.apache.org/book.html">官方教程2</a></li>
</ul>
<h2 id="hbase结构">HBase结构</h2>
<p><img src="hbase-construction.webp"></p>
<h2 id="实验过程">实验过程</h2>
<h3 id="准备阶段">准备阶段</h3>
<h4 id="创建实验用户hadoop">创建实验用户hadoop</h4>
<ul>
<li><p>[再已配置mysql cluster的基础上] 可以采用已有的mysql用户，给mysql用户做相应管理员权限赋权，后续需要用到用户名hadoop的时候，使用mysql</p></li>
<li><p>此处选择新创建hadoop用户</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo useradd -m hadoop -s &#x2F;bin&#x2F;bash  #创建hadoop用户，并使用&#x2F;bin&#x2F;bash作为shell</span><br><span class="line">$ sudo passwd hadoop  #为hadoop用户设置密码，之后需要连续输入两次密码</span><br><span class="line">$ sudo adduser hadoop sudo #为hadoop用户增加管理员权限</span><br><span class="line">$ su - hadoop            #切换当前用户为用户hadoop</span><br><span class="line">$ sudo apt-get update    #更新hadoop用户的apt,方便后面的安装</span><br></pre></td></tr></table></figure>
<p><img src="adduserhadoop.png"></p></li>
</ul>
<h4 id="ssh配置免密登录">SSH配置免密登录</h4>
<ul>
<li><p>安装SSH，设置SSH无密码登陆</p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install openssh-server   #安装SSH server</span><br><span class="line">$ ssh localhost         #登陆SSH，第一次登陆输入yes</span><br><span class="line">$ exit                  #退出登录的ssh localhost</span><br></pre></td></tr></table></figure></p>
<p><img src="ssh-install.png" width=70%></p></li>
<li><p>生成密钥</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd ~&#x2F;.ssh&#x2F;                            #如果没法进入该目录，执行一次ssh localhost</span><br><span class="line">$ ssh-keygen -t rsa　　</span><br><span class="line"># 需要连续敲击三次回车</span><br><span class="line"># 第一次回车是让KEY存于默认位置，以方便后续的命令输入</span><br><span class="line"># 第二次和第三次是确定passphrase，相关性不大</span><br></pre></td></tr></table></figure>
<p><img src="ssh-keygen.png" width=70%></p></li>
<li><p>加入授权，免密登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat .&#x2F;id_rsa.pub &gt;&gt; .&#x2F;authorized_keys  #加入授权</span><br><span class="line">$ ssh localhost  #此时已不需密码即可登录localhost</span><br></pre></td></tr></table></figure>
<p><img src="ssh-authorizedkeys.png" width=70%></p></li>
</ul>
<h3 id="安装jdk1.8">安装jdk1.8</h3>
<ul>
<li><p>在<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">oracle官网</a>下载jdk1.8，根据个人电脑系统选择对应版本，如<code>jdk-8u201-linux-x64.tar.gz</code></p></li>
<li><p>安装过程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ mkdir &#x2F;usr&#x2F;lib&#x2F;jvm  #创建jvm文件夹</span><br><span class="line">$ sudo tar zxvf  jdk-8u201-linux-x64.tar.gz  -C &#x2F;usr&#x2F;lib&#x2F;jvm  #&#x2F; 解压到&#x2F;usr&#x2F;lib&#x2F;jvm目录下</span><br><span class="line">$ cd &#x2F;usr&#x2F;lib&#x2F;jvm  #进入该目录</span><br><span class="line">$ mv  jdk1.8.0_201 java  #重命名为java</span><br><span class="line">$ vi ~&#x2F;.bashrc  #给JDK配置环境变量</span><br></pre></td></tr></table></figure></li>
<li><p>编辑环境变量<code>vi ~/.bashrc</code>，在<code>.bashrc</code>文件添加如下指令： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java</span><br><span class="line">export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre</span><br><span class="line">export CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib:$CLASSPATH</span><br><span class="line">export PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></p>
<p><img src="javaenrpath.png"></p>
<ul>
<li>JAVA_HOME=/usr/lib/jvm/java</li>
</ul></li>
<li><p>使得环境变量生效，并查看是否安装成功 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ source ~&#x2F;.bashrc  #使新配置的环境变量生效</span><br><span class="line">$ java -version  #检测是否安装成功，查看java版本</span><br></pre></td></tr></table></figure></p>
<p><img src="javainstallsuccess.png"></p></li>
</ul>
<h3 id="安装hadoop-3.1.2">安装hadoop-3.1.2</h3>
<ul>
<li>下载<a href="http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz">hadoop-3.1.2.tar.gz</a>并安装 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo tar -zxvf  hadoop-3.1.2.tar.gz  -C  &#x2F;usr&#x2F;local  #解压到&#x2F;usr&#x2F;local目录下</span><br><span class="line">$ cd &#x2F;usr&#x2F;local</span><br><span class="line">$ sudo mv  hadoop-3.1.2 hadoop  #重命名为hadoop</span><br><span class="line">$ sudo chown -R hadoop .&#x2F;hadoop  #修改文件权限，根据实际情况确定用户名</span><br></pre></td></tr></table></figure></li>
<li>配置环境变量，将下面代码添加到<code>.bashrc</code>文件: <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$HADOOP_HOME&#x2F;lib&#x2F;native</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin</span><br></pre></td></tr></table></figure></li>
<li>执行<code>source ~/.bashrc</code>使设置生效，并查看<code>hadoop</code>是否安装成功 <img src="hadoopinstallsuccess.png"></li>
</ul>
<h3 id="伪分布配置">伪分布配置</h3>
<ul>
<li><code>Hadoop</code>可以在单节点上以伪分布式的方式运行，<code>Hadoop</code>进程以分离的<code>Java</code>进程来运行，节点既作为<code>NameNode</code>也作为 <code>DataNode</code>，同时，读取的是<code>HDFS</code>中的文件</li>
<li><code>Hadoop</code>的配置文件位于<code>/usr/local/hadoop/etc/hadoop/</code>中，伪分布式需要修改2个配置文件<code>core-site.xml</code>和<code>hdfs-site.xml</code></li>
<li><code>Hadoop</code>的配置文件是<code>xml</code>格式，每个配置以声明<code>property</code> 的<code>name</code>和<code>value</code>的方式来实现</li>
</ul>
<h4 id="修改hadoop-env.sh文件">修改hadoop-env.sh文件</h4>
<ul>
<li><p>首先将jdk1.8的路径添(<code>export JAVA_HOME=/usr/lib/jvm/java</code>)加到<code>hadoop-env.sh</code>文件，路径为<code>cd /usr/local/hadoop/etc/hadoop/</code></p>
<p><img src="hadoopenv.png" width=70%></p></li>
</ul>
<h4 id="修改core-site.xml文件">修改core-site.xml文件</h4>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  	      <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="core-site.png"></p>
<h4 id="配置hdfs-site.xml文件">配置hdfs-site.xml文件</h4>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="hdfs-site.png"></p>
<ul>
<li><p><code>Hadoop</code>配置文件参数</p>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 46%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="header">
<th>参数</th>
<th>属性值</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>fs.defaultFS</td>
<td>NameNode URI The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem.</td>
<td>hdfs://host:port/</td>
</tr>
<tr class="even">
<td>dfs.namenode.name.dir</td>
<td>Determines where on the local filesystem the DFS name node should store the name table(fsimage) 在本地文件系统所在的NameNode的存储空间和持续化处理日志</td>
<td>如果这是一个以逗号分隔的目录列表，然后将名称表被复制的所有目录，以备不时需</td>
</tr>
<tr class="odd">
<td>dfs.datanode.data.dir</td>
<td>Determines where on the local filesystem an DFS data node should store its blocks 逗号分隔的一个DataNode上，它应该保存它的块的本地文件系统的路径列表</td>
<td>如果这是一个以逗号分隔的目录列表，那么数据将被存储在所有命名的目录，通常在不同的设备</td>
</tr>
</tbody>
</table></li>
<li><p><code>Hadoop</code>的运行方式是由配置文件决定的(运行<code>Hadoop</code>时会读取配置文件)</p></li>
<li><p>因此如果需要从伪分布式模式切换回非分布式模式，需要删除 <code>core-site.xml</code>中的配置项</p></li>
<li><p>伪分布式虽然只需要配置<code>fs.defaultFS</code>和<code>dfs.replication</code>就可以运行（可参考官方教程）</p></li>
<li><p>若没有配置<code>hadoop.tmp.dir</code>参数，则默认使用的临时目录为 <code>/tmp/hadoo-hadoop</code>，而这个目录在重启时有可能被系统清理掉，导致必须重新执行<code>format</code>。所以同时也指定<code>dfs.namenode.name.dir</code>和<code>dfs.datanode.data.dir</code>，否则在接下来的步骤中可能会出错。</p></li>
<li><p>配置完成后，执行 NameNode 的格式化 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;</span><br><span class="line">.&#x2F;bin&#x2F;hdfs namenode –format</span><br></pre></td></tr></table></figure></p>
<p><img src="namenode-format.png"></p>
<p><img src="format-success.png"></p></li>
<li><p>启动<code>namenode</code>和<code>datanode</code>进程，并查看启动结果 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ .&#x2F;sbin&#x2F;start-dfs.sh</span><br><span class="line">$ jps</span><br></pre></td></tr></table></figure></p>
<ul>
<li>启动完成后，可以通过命令<code>jps</code>来判断是否成功启动，若成功启动则会列出如下进程: <code>NameNode</code>、<code>DataNode</code> 和 <code>SecondaryNameNode</code> <img src="start-namenode-datanode.png"></li>
</ul></li>
<li><p>Hadoop出现错误：<code>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</code>，解决方案是在文件<code>hadoop-env.sh</code>中增加：<code>export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"</code></p>
<p><img src="hadoop-warn.png"></p></li>
<li><p>出现<code>ssh: connect to host master port 22: Connection timed out</code></p>
<p><img src="hdfs-ssh-timeout.png"></p>
<ul>
<li><a href="https://www.itread01.com/content/1548390616.html">解决方法：</a>
<ul>
<li><p>查看防火墙</p></li>
<li><p>查看ssh是否开启，22端口是否监听</p></li>
<li><p><code>sudo vi /etc/hosts</code></p>
<p><img src="etc-host.png"></p>
<ul>
<li>127.0.0.1和127.0.1.1都是本地回路/回环地址（区别搜索）</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>有可能出现要求输入localhost密码的情况，如果此时明明输入的是正确的密码却仍无法登入，其原因是由于如果不输入用户名的时候默认的是root用户，但是ssh服务默认没有开root用户的ssh权限</p>
<ul>
<li>输入指令：<code>$vim /etc/ssh/sshd_config</code></li>
<li>PermitRootLogin yes</li>
<li>之后输入下列代码重启SSH服务：<code>$ /etc/init.d/sshd restart</code>，即可正常登入（免密码登录参考前文）</li>
<li>注：Ubuntu 16.04若安装openssh-server，是无法找到/etc/init.d/sshd文件的，但是可以启动/etc/init.d/ssh</li>
</ul></li>
<li><p><a href="https://blog.csdn.net/sinat_19628145/article/details/56494337">secondarynamenode没有启动</a></p></li>
<li><p><a href="https://blog.csdn.net/weixin_38750084/article/details/82856211">NameNode和SecondaryNameNode的区别</a></p></li>
</ul>
<h4 id="访问web界面">访问web界面</h4>
<ul>
<li><p>成功启动后，如果是在桌面版linux上安装的，也可以访问 Web 界面 http://localhost:9870（老版本为50070） 查看NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</p></li>
<li><p>如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost）</p></li>
<li><p>此处配置了静态ip地址为<code>192.18.50.129</code>，在宿主机上输入<code>http://192.168.50.129:9870</code></p>
<p><img src="hadoopweb.png"></p></li>
</ul>
<h4 id="注意">注意</h4>
<ul>
<li>DFS文件系统格式化时，会在namenode数据文件夹（即配置文件中dfs.namenode.name.dir在本地系统的路径）中保存一个current/VERSION文件，记录clusterID，标识了所格式化的 namenode的版本</li>
<li>如果频繁的格式化namenode，那么datanode中保存（即配置文件中dfs.data.dir在本地系统的路径）的current/VERSION文件只是你第一次格式化时保存的namenode的ID，因此就会造成datanode与namenode之间的 id 不一致。可能导致datanode无法启动</li>
</ul>
<h4 id="例子">例子</h4>
<ul>
<li><p>创建执行MapReduce作业所需的 DFS 目录: <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ bin&#x2F;hdfs dfs -mkdir &#x2F;user</span><br><span class="line">$ bin&#x2F;hdfs dfs -mkdir &#x2F;user&#x2F;&lt;username&gt;  #&lt;username&gt; 问用户名，如hadoop</span><br></pre></td></tr></table></figure></p></li>
<li><p>拷贝输入文件到分布式文件系统: <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ bin&#x2F;hdfs dfs -put etc&#x2F;hadoop input</span><br></pre></td></tr></table></figure></p></li>
<li><p>运行一些例子 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.1.jar grep input output &#39;dfs[a-z.]+&#39;</span><br></pre></td></tr></table></figure></p></li>
<li><p>查看输出的文件(files): 从分布式文件系统中拷贝文件到本地文件系统并查看: <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;hdfs dfs -get output output</span><br><span class="line">cat output&#x2F;*</span><br></pre></td></tr></table></figure> 或者直接在分布式文件系统上查看:</p>
<p><code>$ bin/hdfs dfs -cat output/*</code></p>
<p>我也不知道对不对</p>
<p><img src="mapreduce-output.png"></p></li>
<li><p>结束运行<code>sbin/stop-dfs.sh</code></p></li>
</ul>
<h4 id="yarn单机配置">YARN单机配置</h4>
<ul>
<li><p>通过设置几个参数并运行ResourceManager daemon and NodeManager daemon，可以在YARN上以伪分布模式运行MapReduce job</p>
<p>配置mapred-site.xml(cd /usr/local/hadoop/etc/hadoop)如下:</p>
<p><img src="mapred-site.png"></p>
<p>配置yarn-site.xml如下：</p>
<p><img src="yarn-site.png"></p></li>
<li><p>启动ResourceManager daemon 和 NodeManager daemon:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;hadoop</span><br><span class="line">sbin&#x2F;start-yarn.sh</span><br><span class="line"></span><br><span class="line"># 输出如下</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line"></span><br><span class="line">sbin&#x2F;stop-yarn.sh # 关闭</span><br></pre></td></tr></table></figure></li>
<li><p>如果是在桌面版linux上安装的, 可以用浏览器打开资源管理器端口，默认为：ResourceManager - http://localhost:8088/ （如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost） - 同上 <img src="start-yarn.png"></p></li>
</ul>
<h3 id="安装hbase和简单使用">安装Hbase和简单使用</h3>
<h4 id="安装">安装</h4>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 解压安装包hbase-1.2.11-bin.tar.gz至路径 &#x2F;usr&#x2F;local</span><br><span class="line">$ sudo tar -zxvf  hbase-1.2.11-bin.tar.gz -C &#x2F;usr&#x2F;local</span><br><span class="line"># 将解压的文件名hbase-1.2.11改为hbase，以方便使用</span><br><span class="line">$ sudo mv &#x2F;usr&#x2F;local&#x2F;hbase-1.2.11  &#x2F;usr&#x2F;local&#x2F;hbase</span><br><span class="line">cd &#x2F;usr&#x2F;local</span><br><span class="line">$ sudo chown -R hadoop .&#x2F;hbase  # 将hbase下的所有文件的所有者改为hadoop，hadoop是当前用户的用户名。</span><br></pre></td></tr></table></figure>
<h4 id="配置环境变量">配置环境变量</h4>
<ul>
<li><p>给hbase配置环境变量，将下面代码添加到.bashrc文件<code>:export PATH=$PATH:/usr/local/hbase</code></p>
<p><img src="hbase-env.png"></p></li>
<li><p>执行source ~/.bashrc使设置生效，并查看hbase是否安装成功<code>/usr/local/hbase/bin/hbase version</code>或者直接<code>hbase -version</code></p>
<p><img src="hbase-success.png"></p></li>
</ul>
<h4 id="hbase单机配置">hBase单机配置</h4>
<ul>
<li><p>单机配置（可能需要配置JAVA_HOME环境变量，由于本实验指南在HADOOP安装时已配置，故省略）</p></li>
<li><p>配置<code>/usr/local/hbase/conf/hbase-site.xml</code>如下</p>
<p><img src="hbase-site.png"></p></li>
<li><p>采用如下命令启动服务、查看进程和启动客户端 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;hbase</span><br><span class="line">$ bin&#x2F;start-hbase.sh</span><br><span class="line">$ jps</span><br><span class="line">$ bin&#x2F;hbase shell</span><br></pre></td></tr></table></figure></p>
<p><img src="hbase-start.png"></p></li>
</ul>
<h4 id="配置伪分布模式的指南">配置伪分布模式的指南</h4>
<ul>
<li>配置分布模式方法请查阅官方文档</li>
</ul>
<h5 id="配置hbase-env.sh">配置hbase-env.sh</h5>
<ul>
<li><p><code>cd /usr/local/hbase/conf</code>修改<code>hbase-site.xml</code>文件</p>
<p><img src="modify-hbase-site.png"></p>
<p>将HBase的数据存储到之前的Hadoop的HDFS上，hbase.rootdir的值便是HDFS上HBase数据存储的位置，值中的主机名和端口号要和之前Hadoop的core-site.xml中的fs.default.name的值相同</p></li>
<li><p>启动hBase <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先stop-hbase.sh</span><br><span class="line">$ start-dfs.sh</span><br><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;hbase&#x2F;bin</span><br><span class="line">$ .&#x2F;start-hbase.sh</span><br></pre></td></tr></table></figure></p></li>
<li><p>hbase集群在启动的时候报错：JAVA_HOME is not set and Java could not be found出现这种错误，一般应该是hbase下conf文件下的hbase-env.sh文件中的java_home的环境变量没有配置或者是被注释了</p>
<p><img src="java_homeisnotset.png"></p>
<p>解决方法： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;hbase&#x2F;conf</span><br><span class="line">vi hbase-env.sh</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java</span><br></pre></td></tr></table></figure></p>
<p><img src="java_home.png"></p></li>
<li><p>正确顺序：启动Hadoop—&gt;启动HBase—&gt;关闭HBase—&gt;关闭Hadoop</p></li>
<li><p>注：执行jps命令，如果在Hadoop进程的基础上新增加了如下三个进程则表示HBase启动成功：1. HMaster，2. HRegionServer，3. HQuorumpeer</p></li>
</ul>
<h5 id="查看dfs中hbase-目录自动创建">查看DFS中Hbase 目录，自动创建</h5>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~</span><br><span class="line">hdfs dfs -ls &#x2F;hbase</span><br></pre></td></tr></table></figure>
<blockquote>
<p>hadoop@zizi:~$ hdfs dfs -ls /hbase ls: Call From zizi/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused 该问题一般由于没有start dfs 和 yarn造成的</p>
</blockquote>
<p><img src="hdfs-dfs.png"></p>
<ul>
<li><p>仅仅为了测试和学习，生产环境不会在一台机器上启动备份master</p></li>
<li><p>HMaster服务器控制HBase集群，图中的指令启动三个<strong>备份</strong>HMaster，体现了<strong>伪分布式</strong>(在一个机器上多个备份HMaster服务器)，一个HMaster没了，其他的还可以使用</p>
<p><img src="master-backup-start.png"></p>
<p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The HMaster server controls the HBase cluster. You can start up to 9 backup HMaster servers, which makes 10 total HMasters, counting the primary. </span><br><span class="line">To start a backup HMaster, use the local-master-backup.sh. </span><br><span class="line">For each backup master you want to start, add a parameter representing the port offset for that master. </span><br><span class="line">Each HMaster uses two ports (16000 and 16010 by default). </span><br><span class="line">The port offset is added to these ports, so using an offset of 2, the backup HMaster would use ports 16002 and 16012. </span><br><span class="line">The following command starts 3 backup servers using ports 16002&#x2F;16012, 16003&#x2F;16013, and 16005&#x2F;16015.</span><br></pre></td></tr></table></figure></p></li>
<li><p>如：start 1 <img src="master-backup-1.png"></p></li>
<li><p>http://192.168.50.129:16010/master-status可以访问，port=16000无法访问，port=16011可以访问</p>
<p><img src="master-status1.png"></p></li>
<li><p>启动和停止附加区域服务器RegionServers</p>
<p><img src="regionalserver.png"></p></li>
<li><p>关闭刚才开启的备份HMaster服务：<code>local-master-backup.sh stop 1</code></p></li>
</ul>
<h5 id="建表">建表</h5>
<ul>
<li><p>进入交互界面<code>$ hbase shell</code></p>
<p><img src="hbase-shell.png"></p></li>
<li><p>使用create命令创建一个新表，必须规定表名和列族名</p>
<p>使用list 命令可以显示表信息</p>
<p>使用 describe 命令显示表的详细信息，此时表中的VERSIONS默认设置为1</p>
<p><img src="create-list-describe.png"></p></li>
<li><p>向表中加入数据，使用 put 命令</p>
<p>使用scan命令扫描整个表取得数据</p>
<p>取一行数据，使用get指令</p>
<p><img src="put-scan-get.png"></p></li>
<li><p>修改表模式，使用alter命令，如修改存储版本数，为5个版本</p>
<p><img src="alter-version.png"></p></li>
</ul>
<h2 id="实验总结">实验总结</h2>
<ol type="1">
<li><p>请问伪分布和分布式的含义有何不同？就本实验，你是如何理解在一台计算机上做到“伪分布”的？</p>
<ul>
<li>伪分布式模式是一个相对简单的分布式模式，用来测试</li>
<li>不能把这个模式用于生产环节，也不能用于测试性能。</li>
<li>多个HMaster备份节点在一台机器上工作</li>
</ul></li>
<li><p>在1.2小节进行安装SSH并设置SSH无密码登陆，请问这个安装的目的是什么？ &gt; ssh must be installed and sshd must be running to use the Hadoop scripts that manage remote Hadoop daemons if the optional start and stop scripts are to be used. Additionally, it is recommmended that pdsh also be installed for better ssh resource management.</p>
<ul>
<li>ssh必须安装，sshd必须运行，Hadoop的脚本才可以远程操控其他的Hadoop和HBase进程</li>
<li>ssh之间必须都打通，远程登录、自动登录、免密登录</li>
</ul></li>
<li><p>如果继续向Hbase的test表中put行键为”row1”，值为其它字符串的数据，put 'test' ,'row1', 'cf:a', 'value6'，会发生什么？如果采用语句get 'test', 'row1', {COLUMN=&gt;'cf:a', VERSIONS=&gt;3} 进行查询，分析你得到的结果。put与关系数据库的插入有何不同？</p>
<p><img src="put.png"></p>
<ul>
<li>VERSIONS的作用
<ul>
<li>当想要用HBase存储历史几个版本的数据是（达到类似于git的效果时）可以设定版本号，版本号为几就是存储几个版本的数据</li>
<li>最开始，没有设定VERSION，则为VERSIONS为1，也就是说，默认情况只会存取一个版本的列数据，当再次插入的时候，后面的值会覆盖前面的值</li>
<li>后面修改表结构，让Hbase表支持存储5个VERSIONS的版本列数据 alter 'test', NAME=&gt;'cf',VERSIONS=&gt;5</li>
<li>解析：一开始row1只有一条数据，然后又插入了第二条数据，虽然scan 'test'只返回最新的数据，但是用get那条语句能够返回历史版本，所以返回两条数据 <img src="versions.png"></li>
</ul></li>
</ul></li>
</ol>
<h2 id="错误与解决">错误与解决</h2>
<ul>
<li>如何执行shell脚本！！！-牢记 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop@zizi:&#x2F;usr&#x2F;local&#x2F;hbase&#x2F;bin$ local-master-backup.sh start 2 3 5</span><br><span class="line">local-master-backup.sh: command not found</span><br></pre></td></tr></table></figure></li>
<li><a href="https://blog.csdn.net/tiankong_12345/article/details/93585463">Hbase启动警告：Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m;</a></li>
<li>hBase中get和scan的区别和总结</li>
</ul>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://www.jianshu.com/p/6aeceb5d49cf">HBase入门精要-百闻不如一Run</a></li>
<li><a href="https://www.jianshu.com/p/b23800d9b227">入门HBase，看这一篇就够了</a></li>
</ul>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Hadoop/">Hadoop</a><a class="link-muted mr-2" rel="tag" href="/tags/Hbase/">Hbase</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/09/Software-Security/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">软件安全概述</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/04/12/Number-Theory/"><span class="level-item">Number Theory</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/channel.png" alt="purplezi"></figure><p class="title is-size-4 is-block line-height-inherit">purplezi</p><p class="is-size-6 is-block">Lazy, foolish</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">19</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/purplezi" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/purplezi"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#实验环境"><span class="mr-2">1</span><span>实验环境</span></a></li><li><a class="is-flex" href="#hbase结构"><span class="mr-2">2</span><span>HBase结构</span></a></li><li><a class="is-flex" href="#实验过程"><span class="mr-2">3</span><span>实验过程</span></a><ul class="menu-list"><li><a class="is-flex" href="#准备阶段"><span class="mr-2">3.1</span><span>准备阶段</span></a><ul class="menu-list"><li><a class="is-flex" href="#创建实验用户hadoop"><span class="mr-2">3.1.1</span><span>创建实验用户hadoop</span></a></li><li><a class="is-flex" href="#ssh配置免密登录"><span class="mr-2">3.1.2</span><span>SSH配置免密登录</span></a></li></ul></li><li><a class="is-flex" href="#安装jdk1.8"><span class="mr-2">3.2</span><span>安装jdk1.8</span></a></li><li><a class="is-flex" href="#安装hadoop-3.1.2"><span class="mr-2">3.3</span><span>安装hadoop-3.1.2</span></a></li><li><a class="is-flex" href="#伪分布配置"><span class="mr-2">3.4</span><span>伪分布配置</span></a><ul class="menu-list"><li><a class="is-flex" href="#修改hadoop-env.sh文件"><span class="mr-2">3.4.1</span><span>修改hadoop-env.sh文件</span></a></li><li><a class="is-flex" href="#修改core-site.xml文件"><span class="mr-2">3.4.2</span><span>修改core-site.xml文件</span></a></li><li><a class="is-flex" href="#配置hdfs-site.xml文件"><span class="mr-2">3.4.3</span><span>配置hdfs-site.xml文件</span></a></li><li><a class="is-flex" href="#访问web界面"><span class="mr-2">3.4.4</span><span>访问web界面</span></a></li><li><a class="is-flex" href="#注意"><span class="mr-2">3.4.5</span><span>注意</span></a></li><li><a class="is-flex" href="#例子"><span class="mr-2">3.4.6</span><span>例子</span></a></li><li><a class="is-flex" href="#yarn单机配置"><span class="mr-2">3.4.7</span><span>YARN单机配置</span></a></li></ul></li><li><a class="is-flex" href="#安装hbase和简单使用"><span class="mr-2">3.5</span><span>安装Hbase和简单使用</span></a><ul class="menu-list"><li><a class="is-flex" href="#安装"><span class="mr-2">3.5.1</span><span>安装</span></a></li><li><a class="is-flex" href="#配置环境变量"><span class="mr-2">3.5.2</span><span>配置环境变量</span></a></li><li><a class="is-flex" href="#hbase单机配置"><span class="mr-2">3.5.3</span><span>hBase单机配置</span></a></li><li><a class="is-flex" href="#建表"><span class="mr-2">3.5.4</span><span>建表</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#实验总结"><span class="mr-2">4</span><span>实验总结</span></a></li><li><a class="is-flex" href="#错误与解决"><span class="mr-2">5</span><span>错误与解决</span></a></li><li><a class="is-flex" href="#参考资料"><span class="mr-2">6</span><span>参考资料</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/ACM/"><span class="level-start"><span class="level-item">ACM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Blogs/"><span class="level-start"><span class="level-item">Blogs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/DataBase/"><span class="level-start"><span class="level-item">DataBase</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Security/"><span class="level-start"><span class="level-item">Security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-01-15T10:43:21.000Z">2021-01-15</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/15/icarus/">icarus-一个hexo主题美化过程</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-01-11T11:33:45.000Z">2021-01-11</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/11/web-notes/">白帽子讲web安全</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-20T01:25:45.000Z">2020-07-20</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/20/ipaddress/">IP地址</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-21T13:05:05.000Z">2020-06-21</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/21/aliyun-sfim/">阿里云服务器(centos7系统) 使用nginx+uwsgi 部署python+flask项目</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-13T15:18:25.000Z">2020-06-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/13/binary-safe/">软件安全中的二进制安全</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Security/">Security</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Cluster/"><span class="tag">Cluster</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hbase/"><span class="tag">Hbase</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MkDocs/"><span class="tag">MkDocs</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Security/"><span class="tag">Security</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travis/"><span class="tag">Travis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql/"><span class="tag">mysql</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nginx/"><span class="tag">nginx</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/security/"><span class="tag">security</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/uwsgi/"><span class="tag">uwsgi</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web-security/"><span class="tag">web security</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web-server/"><span class="tag">web server</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/xss/"><span class="tag">xss</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E8%AE%BA/"><span class="tag">数论</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/plant-pot.svg" alt="Purplezi" height="28"></a><p class="size-small"><span>&copy; 2021 Purplezi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://purplezi.gitee.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>