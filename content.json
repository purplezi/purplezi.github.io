{"pages":[{"title":"English","text":"","link":"/English/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"about","text":"Hello World","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"photos","text":"","link":"/photos/index.html"}],"posts":[{"title":"NoSQL数据库系统Hadoop-Hbase安装配置(伪分布模式)与简单使用","text":"/* 设置整个页面的字体 */ html, body, .markdown-body { font-family: Georgia, sans, serif; font-size: 15px; } /* 只设置 markdown 字体 */ .markdown-body { font-family: Georgia, sans, serif; font-size: 15px; } Hbase是一种NoSQL数据库，这意味着它不像传统的RDBMS(关系数据库管理系统 Relational Database Management System)数据库那样支持SQL作为查询语言 Hbase是一种分布式存储的数据库，技术上来讲，它更像是分布式存储而不是分布式数据库 数据库量要足够多，如果有十亿及百亿行数据，那么Hbase是一个很好的选项，如果只有几百万行甚至不到的数据量，RDBMS是一个很好的选择。因为数据量小的话，真正能工作的机器量少，剩余的机器都处于空闲的状态 保证硬件资源足够，每个HDFS集群在少于5个节点的时候，都不能表现的很好。因为HDFS默认的复制数量是3，再加上一个NameNode 实验环境 VMware Workstation Pro 12 系统为Ubuntu 16.04 Server的Linux虚拟机 jdk-8u201-linux-x64.tar.gz，校验和 hadoop-3.1.2.tar.gz，校验和 hbase-1.2.11-bin.tar.gz，校验和 官方教程1、官方教程2 HBase结构 实验过程 准备阶段 创建实验用户hadoop [再已配置mysql cluster的基础上] 可以采用已有的mysql用户，给mysql用户做相应管理员权限赋权，后续需要用到用户名hadoop的时候，使用mysql 此处选择新创建hadoop用户 $ sudo useradd -m hadoop -s /bin/bash #创建hadoop用户，并使用/bin/bash作为shell$ sudo passwd hadoop #为hadoop用户设置密码，之后需要连续输入两次密码$ sudo adduser hadoop sudo #为hadoop用户增加管理员权限$ su - hadoop #切换当前用户为用户hadoop$ sudo apt-get update #更新hadoop用户的apt,方便后面的安装 SSH配置免密登录 安装SSH，设置SSH无密码登陆 $ sudo apt-get install openssh-server #安装SSH server$ ssh localhost #登陆SSH，第一次登陆输入yes$ exit #退出登录的ssh localhost 生成密钥 $ cd ~/.ssh/ #如果没法进入该目录，执行一次ssh localhost$ ssh-keygen -t rsa # 需要连续敲击三次回车# 第一次回车是让KEY存于默认位置，以方便后续的命令输入# 第二次和第三次是确定passphrase，相关性不大 加入授权，免密登录 $ cat ./id_rsa.pub &gt;&gt; ./authorized_keys #加入授权$ ssh localhost #此时已不需密码即可登录localhost 安装jdk1.8 在oracle官网下载jdk1.8，根据个人电脑系统选择对应版本，如jdk-8u201-linux-x64.tar.gz 安装过程 $ mkdir /usr/lib/jvm #创建jvm文件夹$ sudo tar zxvf jdk-8u201-linux-x64.tar.gz -C /usr/lib/jvm #/ 解压到/usr/lib/jvm目录下$ cd /usr/lib/jvm #进入该目录$ mv jdk1.8.0_201 java #重命名为java$ vi ~/.bashrc #给JDK配置环境变量 编辑环境变量vi ~/.bashrc，在.bashrc文件添加如下指令： export JAVA_HOME=/usr/lib/jvm/javaexport JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATHexport PATH=${JAVA_HOME}/bin:$PATH JAVA_HOME=/usr/lib/jvm/java 使得环境变量生效，并查看是否安装成功 $ source ~/.bashrc #使新配置的环境变量生效$ java -version #检测是否安装成功，查看java版本 安装hadoop-3.1.2 下载hadoop-3.1.2.tar.gz并安装 $ sudo tar -zxvf hadoop-3.1.2.tar.gz -C /usr/local #解压到/usr/local目录下$ cd /usr/local$ sudo mv hadoop-3.1.2 hadoop #重命名为hadoop$ sudo chown -R hadoop ./hadoop #修改文件权限，根据实际情况确定用户名 配置环境变量，将下面代码添加到.bashrc文件: export HADOOP_HOME=/usr/local/hadoopexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 执行source ~/.bashrc使设置生效，并查看hadoop是否安装成功 伪分布配置 Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的Java进程来运行，节点既作为NameNode也作为 DataNode，同时，读取的是HDFS中的文件 Hadoop的配置文件位于/usr/local/hadoop/etc/hadoop/中，伪分布式需要修改2个配置文件core-site.xml和hdfs-site.xml Hadoop的配置文件是xml格式，每个配置以声明property 的name和value的方式来实现 修改hadoop-env.sh文件 首先将jdk1.8的路径添(export JAVA_HOME=/usr/lib/jvm/java)加到hadoop-env.sh文件，路径为cd /usr/local/hadoop/etc/hadoop/ 修改core-site.xml文件 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml文件 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Hadoop配置文件参数 参数 属性值 解释 fs.defaultFS NameNode URI The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem. hdfs://host:port/ dfs.namenode.name.dir Determines where on the local filesystem the DFS name node should store the name table(fsimage) 在本地文件系统所在的NameNode的存储空间和持续化处理日志 如果这是一个以逗号分隔的目录列表，然后将名称表被复制的所有目录，以备不时需 dfs.datanode.data.dir Determines where on the local filesystem an DFS data node should store its blocks 逗号分隔的一个DataNode上，它应该保存它的块的本地文件系统的路径列表 如果这是一个以逗号分隔的目录列表，那么数据将被存储在所有命名的目录，通常在不同的设备 Hadoop的运行方式是由配置文件决定的(运行Hadoop时会读取配置文件) 因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml中的配置项 伪分布式虽然只需要配置fs.defaultFS和dfs.replication就可以运行（可参考官方教程） 若没有配置hadoop.tmp.dir参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行format。所以同时也指定dfs.namenode.name.dir和dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。 配置完成后，执行 NameNode 的格式化 cd /usr/local/hadoop/./bin/hdfs namenode –format 启动namenode和datanode进程，并查看启动结果 $ ./sbin/start-dfs.sh$ jps 启动完成后，可以通过命令jps来判断是否成功启动，若成功启动则会列出如下进程: NameNode、DataNode 和 SecondaryNameNode Hadoop出现错误：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable，解决方案是在文件hadoop-env.sh中增加：export HADOOP_OPTS=\"-Djava.library.path=${HADOOP_HOME}/lib/native\" 出现ssh: connect to host master port 22: Connection timed out 解决方法： 查看防火墙 查看ssh是否开启，22端口是否监听 sudo vi /etc/hosts 127.0.0.1和127.0.1.1都是本地回路/回环地址（区别搜索） 有可能出现要求输入localhost密码的情况，如果此时明明输入的是正确的密码却仍无法登入，其原因是由于如果不输入用户名的时候默认的是root用户，但是ssh服务默认没有开root用户的ssh权限 输入指令：$vim /etc/ssh/sshd_config PermitRootLogin yes 之后输入下列代码重启SSH服务：$ /etc/init.d/sshd restart，即可正常登入（免密码登录参考前文） 注：Ubuntu 16.04若安装openssh-server，是无法找到/etc/init.d/sshd文件的，但是可以启动/etc/init.d/ssh secondarynamenode没有启动 NameNode和SecondaryNameNode的区别 访问web界面 成功启动后，如果是在桌面版linux上安装的，也可以访问 Web 界面 http://localhost:9870（老版本为50070） 查看NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。 如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost） 此处配置了静态ip地址为192.18.50.129，在宿主机上输入http://192.168.50.129:9870 注意 DFS文件系统格式化时，会在namenode数据文件夹（即配置文件中dfs.namenode.name.dir在本地系统的路径）中保存一个current/VERSION文件，记录clusterID，标识了所格式化的 namenode的版本 如果频繁的格式化namenode，那么datanode中保存（即配置文件中dfs.data.dir在本地系统的路径）的current/VERSION文件只是你第一次格式化时保存的namenode的ID，因此就会造成datanode与namenode之间的 id 不一致。可能导致datanode无法启动 例子 创建执行MapReduce作业所需的 DFS 目录: $ bin/hdfs dfs -mkdir /user$ bin/hdfs dfs -mkdir /user/&lt;username&gt; #&lt;username&gt; 问用户名，如hadoop 拷贝输入文件到分布式文件系统: $ bin/hdfs dfs -put etc/hadoop input 运行一些例子 bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+' 查看输出的文件(files): 从分布式文件系统中拷贝文件到本地文件系统并查看: bin/hdfs dfs -get output outputcat output/* 或者直接在分布式文件系统上查看: $ bin/hdfs dfs -cat output/* 我也不知道对不对 结束运行sbin/stop-dfs.sh YARN单机配置 通过设置几个参数并运行ResourceManager daemon and NodeManager daemon，可以在YARN上以伪分布模式运行MapReduce job 配置mapred-site.xml(cd /usr/local/hadoop/etc/hadoop)如下: 配置yarn-site.xml如下： 启动ResourceManager daemon 和 NodeManager daemon: cd /usr/local/hadoopsbin/start-yarn.sh# 输出如下Starting resourcemanagerStarting nodemanagerssbin/stop-yarn.sh # 关闭 如果是在桌面版linux上安装的, 可以用浏览器打开资源管理器端口，默认为：ResourceManager - http://localhost:8088/ （如果是在服务器版linux上安装的hadoop, 为了进行浏览器访问，需要配置一个桌面版的虚拟机来进行，输入用IP地址代替localhost） - 同上 安装Hbase和简单使用 安装 # 解压安装包hbase-1.2.11-bin.tar.gz至路径 /usr/local$ sudo tar -zxvf hbase-1.2.11-bin.tar.gz -C /usr/local# 将解压的文件名hbase-1.2.11改为hbase，以方便使用$ sudo mv /usr/local/hbase-1.2.11 /usr/local/hbasecd /usr/local$ sudo chown -R hadoop ./hbase # 将hbase下的所有文件的所有者改为hadoop，hadoop是当前用户的用户名。 配置环境变量 给hbase配置环境变量，将下面代码添加到.bashrc文件:export PATH=$PATH:/usr/local/hbase 执行source ~/.bashrc使设置生效，并查看hbase是否安装成功/usr/local/hbase/bin/hbase version或者直接hbase -version hBase单机配置 单机配置（可能需要配置JAVA_HOME环境变量，由于本实验指南在HADOOP安装时已配置，故省略） 配置/usr/local/hbase/conf/hbase-site.xml如下 采用如下命令启动服务、查看进程和启动客户端 $ cd /usr/local/hbase$ bin/start-hbase.sh$ jps$ bin/hbase shell 配置伪分布模式的指南 配置分布模式方法请查阅官方文档 配置hbase-env.sh cd /usr/local/hbase/conf修改hbase-site.xml文件 将HBase的数据存储到之前的Hadoop的HDFS上，hbase.rootdir的值便是HDFS上HBase数据存储的位置，值中的主机名和端口号要和之前Hadoop的core-site.xml中的fs.default.name的值相同 启动hBase # 先stop-hbase.sh$ start-dfs.sh$ cd /usr/local/hbase/bin$ ./start-hbase.sh hbase集群在启动的时候报错：JAVA_HOME is not set and Java could not be found出现这种错误，一般应该是hbase下conf文件下的hbase-env.sh文件中的java_home的环境变量没有配置或者是被注释了 解决方法： cd /usr/local/hbase/confvi hbase-env.shexport JAVA_HOME=/usr/lib/jvm/java 正确顺序：启动Hadoop—&gt;启动HBase—&gt;关闭HBase—&gt;关闭Hadoop 注：执行jps命令，如果在Hadoop进程的基础上新增加了如下三个进程则表示HBase启动成功：1. HMaster，2. HRegionServer，3. HQuorumpeer 查看DFS中Hbase 目录，自动创建 cd ~hdfs dfs -ls /hbase hadoop@zizi:~$ hdfs dfs -ls /hbase ls: Call From zizi/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused 该问题一般由于没有start dfs 和 yarn造成的 仅仅为了测试和学习，生产环境不会在一台机器上启动备份master HMaster服务器控制HBase集群，图中的指令启动三个备份HMaster，体现了伪分布式(在一个机器上多个备份HMaster服务器)，一个HMaster没了，其他的还可以使用 The HMaster server controls the HBase cluster. You can start up to 9 backup HMaster servers, which makes 10 total HMasters, counting the primary. To start a backup HMaster, use the local-master-backup.sh. For each backup master you want to start, add a parameter representing the port offset for that master. Each HMaster uses two ports (16000 and 16010 by default). The port offset is added to these ports, so using an offset of 2, the backup HMaster would use ports 16002 and 16012. The following command starts 3 backup servers using ports 16002/16012, 16003/16013, and 16005/16015. 如：start 1 http://192.168.50.129:16010/master-status可以访问，port=16000无法访问，port=16011可以访问 启动和停止附加区域服务器RegionServers 关闭刚才开启的备份HMaster服务：local-master-backup.sh stop 1 建表 进入交互界面$ hbase shell 使用create命令创建一个新表，必须规定表名和列族名 使用list 命令可以显示表信息 使用 describe 命令显示表的详细信息，此时表中的VERSIONS默认设置为1 向表中加入数据，使用 put 命令 使用scan命令扫描整个表取得数据 取一行数据，使用get指令 修改表模式，使用alter命令，如修改存储版本数，为5个版本 实验总结 请问伪分布和分布式的含义有何不同？就本实验，你是如何理解在一台计算机上做到“伪分布”的？ 伪分布式模式是一个相对简单的分布式模式，用来测试 不能把这个模式用于生产环节，也不能用于测试性能。 多个HMaster备份节点在一台机器上工作 在1.2小节进行安装SSH并设置SSH无密码登陆，请问这个安装的目的是什么？ &gt; ssh must be installed and sshd must be running to use the Hadoop scripts that manage remote Hadoop daemons if the optional start and stop scripts are to be used. Additionally, it is recommmended that pdsh also be installed for better ssh resource management. ssh必须安装，sshd必须运行，Hadoop的脚本才可以远程操控其他的Hadoop和HBase进程 ssh之间必须都打通，远程登录、自动登录、免密登录 如果继续向Hbase的test表中put行键为”row1”，值为其它字符串的数据，put 'test' ,'row1', 'cf:a', 'value6'，会发生什么？如果采用语句get 'test', 'row1', {COLUMN=&gt;'cf:a', VERSIONS=&gt;3} 进行查询，分析你得到的结果。put与关系数据库的插入有何不同？ VERSIONS的作用 当想要用HBase存储历史几个版本的数据是（达到类似于git的效果时）可以设定版本号，版本号为几就是存储几个版本的数据 最开始，没有设定VERSION，则为VERSIONS为1，也就是说，默认情况只会存取一个版本的列数据，当再次插入的时候，后面的值会覆盖前面的值 后面修改表结构，让Hbase表支持存储5个VERSIONS的版本列数据 alter 'test', NAME=&gt;'cf',VERSIONS=&gt;5 解析：一开始row1只有一条数据，然后又插入了第二条数据，虽然scan 'test'只返回最新的数据，但是用get那条语句能够返回历史版本，所以返回两条数据 错误与解决 如何执行shell脚本！！！-牢记 hadoop@zizi:/usr/local/hbase/bin$ local-master-backup.sh start 2 3 5local-master-backup.sh: command not found Hbase启动警告：Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; hBase中get和scan的区别和总结 参考资料 HBase入门精要-百闻不如一Run 入门HBase，看这一篇就够了","link":"/2020/05/15/Hadoop-Hbase/"},{"title":"MkDocs+Github+Travis搭建博客","text":"最近是不是玩博客玩疯了 大概逻辑：通过Travis CI部署的MkDocs环境生成静态页面并且发布到GitHub上 能够通过https://xxx.github.io/访问 MkDocs 官网 1. https://squidfunk.github.io/mkdocs-material/ 2. https://www.mkdocs.org/ Travis 官网 https://travis-ci.org Github 建立仓库后，git clone仓库到本地 MkDocs 使用简介 [最好看文档] 安装 # 查看python和pip版本python --versionpip --version# Installing and verifying MkDocs # Material requires MkDocs &gt;= 1.0.0.pip install mkdocs &amp;&amp; mkdocs --version# install materialpip install mkdocs-material 使用 # 创建文档库# xxx是目录名称 会生成docs文件夹和mkdocs.ymlmkdocs new xxx# 启用服务mkdocs serve# 编译构建站点mkdocs build 至于页面的样式，看文档更改mkdocs.yml文件 部署到Github 将克隆下来的仓库切到master主分支 将上述产生的docs文件夹和mkdocs.yml放入该git目录下 自动编译并发布至Github gh-pages分支 mkdocs gh-deploy --clean# 可以 mkdocs serve 看看是否能够正常显示 将本地的仓库同步远程 git add -Agit push 通过https:xxx.github.io/仓库名称访问 Travis 持续集成服务 看起来像是监控每一次的提交修改的情况 直接附上教程 References 使用MKdocs搭建个人博客并发布在Github Pages上 基于mkdocs-material搭建个人静态博客","link":"/2020/03/21/MkDocs-Github-Travis/"},{"title":"部署MySQL Cluster集群系统","text":"MySQL Cluster is a technology providing shared-nothing clustering and auto-sharding for the MySQL database management system. It is designed to provide high availability and high throughput with low latency, while allowing for near linear scalability A MySQL Cluster consists of one or more management nodes (ndb_mgmd) that store the cluster’s configuration and control the data nodes (ndbd), where cluster data is stored. After communicating with the management node, clients (MySQL clients, servers, or native APIs) connect directly to these data nodes. With MySQL Cluster there is typically no replication of data, but instead data node synchronization. For this purpose a special data engine must be used — NDBCluster (NDB) 1 实验环境 英文指南(18.04&amp;16.04) VMware Workstation Pro 12 2台Linux虚拟机，Ubuntu 16.04 Server MySQL-Cluster的安装包：mysql-cluster_8.0.19-1ubuntu16.04_amd64.deb-bundle.tar 设置windows主机和Linux虚拟机共享文件夹 方便编辑配置文件，安装vim sudo apt-get install vim 2 实验过程 2.1 前提 在VMware下安装Ubuntu虚拟机 VMware的克隆，右键虚拟机-&gt;管理-&gt;克隆，创建完整克隆 两个不同的虚拟机如果是用同一个镜像报错内部错误 -&gt; 就像virtualbox中的多重加载 所以用一个iso安装好一个虚拟机后，将使用ISO映像文件去掉，选择使用物理驱动器。再用这个iso装另外的机器。克隆同理。 虚拟机与宿主机共享 注意用cp而不是mv将vmware tools安装包移动到可以进行解压gunzip的目录，如'/root'。因为该安装包只读，所以无法在该文件夹下进行解压和mv命令 tar格式(tar是打包，不是压缩) 打包:tar cvf 目录文件名.tar 目录文件名解包:tar xvf 目录文件名.tar tar.gz格式： 压缩:tar -zcvf 目录文件名.tar.gz 目录文件名解压:tar -zxvf 目录文件名.tar.gz 2.2 设置静态IP 2.2.1 VMware配置网络环境 按要求给一台机器设置静态ip为：192.168.50.128，另一台机器的静态ip为：192.168.50.129。 使用NAT，虚拟机在一个子网中，通过物理机的IP上网。 去掉使用本地DHCP服务将IP地址分配给虚拟机，并且设置子网IP为：192.168.50.0，子网掩码为：255.255.255.0。因此，在Ubuntu中，设置IP地址的时候，可以设置为192.168.50.x，x可以为1~255。 选择NAT设置，打开NAT设置面板，查看网关地址。 在VMWare的虚拟机管理界面，选择Ubuntu的编辑虚拟机设置，打开Ubuntu这个虚拟的设置界面。选择网络适配器，然后确定网络连接选中的是自定义中的VMnet8(NAT模式)。 2.2.2 为Ubuntu设置静态IP地址 通过Terminal命令行来设置IP地址 在命令行输入 sudo vi /etc/network/interfaces # 在打开的文件中，若有内容，先全部删除# 然后输入如下代码# ip a查看网卡信息是ens33auto loiface lo inet loopbackauto ens33iface ens33 inet staticaddress 192.168.50.128netmask 255.255.255.0gateway 192.168.50.2 配置DNS服务器 sudo vi /etc/resolv.conf# 在里面填入阿里的DNS：223.5.5.5nameserver 223.5.5.5# 在命令行中输入：sudo /etc/init.d/networking restart 重复以上步骤，配置第二个虚拟机的静态IP地址。 2.3 集群配置 2.3.1 集群配置要求 拓扑图 集群配置要求 # ndbd：MySQL data nodes# ndb_mgmd：server for the Cluster Manager# mysqld and mysql：MySQL server/client 节点 IP address 运行实例 nodeID 数据节点1 192.168.50.128 ndbd 11 数据节点2 192.168.50.129 ndbd 12 管理节点 192.168.50.129 ndb_mgmd 1 sql节点1 192.168.50.129 mysqld 13 sql节点2 192.168.50.128 mysqld 14 一般配置，数据节点和管理节点分离(需要3台虚拟机模拟实现)。由于此处只用了2台虚拟机。 MySQL-Cluster的安装包下载，根据linux操作系统选择正确的版本 若之前安装过mysql-server，需要将mysql-server卸载 # 执行以下指令卸载mysqlsudo apt-get autoremove --purge mysql-serversudo apt-get remove mysql-serversudo apt-get autoremove mysql-serversudo apt-get remove mysql-common 2.3.2 准备阶段 针对192.168.50.129，安装 # 在命令行下sudo adduser mysqlsudo usermod -aG sudo mysql 把下载的mysql-cluster_8.0.19-1ubuntu16.04_amd64.deb-bundle.tar从windows共享给虚拟机(通过共享文件夹) 将MySQL-Cluster的安装包放入虚拟机的指定目录install文件夹，操作如下： # 在命令行的根目录下mkdir install# 通过共享文件夹tar -xvf /mnt/hgfs/xxx/mysql-cluster_8.0.19-1ubuntu16.04_amd64.deb-bundle.tar -C install/cd install 安装MySQL server binary # 安装依赖包sudo apt update# sudo apt-get updatesudo apt-get upgradesudo apt-get install libaio1 libmecab2 2.3.3 安装配置集群管理器 用dpkg指令在Cluster Manager 服务器(为192.168.50.129)上安装ndb_mgmd # 进入install目录sudo dpkg -i mysql-cluster-community-management-server_8.0.19-1ubuntu16.04_amd64.deb 在第一次运行ndb_mgmd前需要对其进行配置，正确配置是保证数据节点正确同步和负载分配的前提。 Cluster Manager 应该是MySQL Cluster 第一个启动的组件.它需要一个配置文件来加载参数. 我门创建配置文件: /var/lib/mysql-cluster/config.ini. # 从Windows编辑config.ini可能会报错，需要在Linux系统下编辑# 在Cluster Manager 所在机器上创建 /var/lib/mysql-cluster目录:sudo mkdir /var/lib/mysql-clustersudo vim /var/lib/mysql-cluster/config.ini# 内容如下[ndbd default]# Options affecting ndbd processes on all data nodes:NoOfReplicas=2 # Number of replicas[ndb_mgmd]# Management process options:hostname=192.168.50.129 # Hostname of the managerNodeId=1datadir=/var/lib/mysql-cluster # Directory for the log files[ndbd]hostname=192.168.50.128 # Hostname/IP of the first data nodeNodeId=11 # Node ID for this data nodedatadir=/usr/local/mysql/data # Remote directory for the data files[ndbd]hostname=192.168.50.129 # Hostname/IP of the second data nodeNodeId=12 # Node ID for this data nodedatadir=/usr/local/mysql/data # Remote directory for the data files[mysqld]# SQL node options:hostname=192.168.50.129 # MySQL server/client i manager[mysqld]# SQL node options:hostname=192.168.50.128 # MySQL server/client i manager [NDB_MGMD] 表示管理节点的配置，只能有一个 [NDBD DEFAULT] 表示每个数据节点的默认配置，在每个节点的[NDBD]中不用再写这些选项，只能有一个 [NDBD] 表示每个数据节点的配置，可以有多个 [MYSQLD] 表示SQL节点的配置，可以有多个，分别写上不同的SQL节点的ip地址；如不写，只保留一个空节点，表示任意一个ip地址都可以进行访问。此节点的个数表明了可以用来连接数据节点的SQL节点总数 每个节点都有一个独立的id号，可以填写，比如nodeid=2，老版本使用id，新版本已经不使用id标识了。不填写，系统会按照配置文件的填写顺序自动分配 如果是生产环境，应该根据实际情况调整配置参数，参考MySQL Cluster. 你还可以增加 data nodes (ndbd) 或 MySQL server nodes (mysqld). 启动管理器 # 查看是否有正在运行的服务进程ps -aux | grep ndb_mgmd# 在启动服务前，可能需要杀掉正在运行的服务:sudo pkill -f ndb_mgmd# 启动服务sudo ndb_mgmd -f /var/lib/mysql-cluster/config.ini#检查ndb_mgmd 使用的端口 1186sudo netstat -plntu 配置自动加载服务 # 在Ubuntu虚拟机下# 打开并编辑下面 systemd Unit 文件sudo vim /etc/systemd/system/ndb_mgmd.service# 键入以下内容，保存并关闭[Unit]Description=MySQL NDB Cluster Management ServerAfter=network.target auditd.service[Service]Type=forkingExecStart=/usr/sbin/ndb_mgmd -f /var/lib/mysql-cluster/config.iniExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failure[Install]WantedBy=multi-user.target# 上面只是加入了如何启动、停止和重启动ndb_mgmd进程的最小选项集合# more information，参阅[systemd manual](https://www.freedesktop.org/software/systemd/man/systemd.service.html). # reload systemd’s manager configuration using daemon-reloadsudo systemctl daemon-reload# enable the service we just created# MySQL Cluster Manager starts on rebootsudo systemctl enable ndb_mgmd# start the servicesudo systemctl start ndb_mgmd# verify that the NDB Cluster Management service is runningsudo systemctl status ndb_mgmd ndb_mgmdMySQL Cluster Management server作为一个系统服务正在运行 设置Cluster Manager允许其它MySQL Cluster节点连入 如果出现连接问题，则需要设置ufw防火墙，添加允许数据节点连入的规则 sudo ufw allow from 192.168.50.128sudo ufw allow from 192.168.50.129 会见到如下输出。此时Cluster Manager应该启动运行了，并且能够通过局域网与集群其它节点通信了。 Rule added# 因为我之前配置过，所以会显示Rule updated 2.3.4 配置数据节点 假定在192.168.50.129上进行(同理另一个节点) 安装依赖包 # 修复损坏的软件包，尝试卸载出错的包，重新安装正确版本的sudo apt-get –f install sudo apt install libclass-methodmaker-perl 安装数据节点包 # 进入install文件夹sudo dpkg -i mysql-cluster-community-data-node_8.0.19-1ubuntu16.04_amd64.deb 数据节点将从固定位置/etc/my.cnf获取配置文件.创建文件并编辑 sudo vim /etc/my.cnf# 写入以下内容 两个虚拟机都一样[mysql_cluster]# Options for NDB Cluster processes:ndb-connectstring=192.168.50.129 # location of cluster manager 本配置设定在管理器配置数据目录为/usr/local/mysql/data。运行服务前要创建相关目录sudo mkdir -p /usr/local/mysql/data。在成功启动数据节点的时候，会向该文件夹中写入数据，如下图所示。 启动服务sudo ndbd，NDB 数据节点守护程序成功启动 同理见192.168.50.128(192.168.50.129机器上的管理器服务要打开) 如果出现连接问题，请打开防火墙： sudo ufw allow from 192.168.50.129sudo ufw allow from 192.168.50.128 同配置集群管理器类似，配置数据节点服务自启动 # 打开并编辑如下 systemd Unit 文件sudo vim /etc/systemd/system/ndbd.service# 内容如下：[Unit]Description=MySQL NDB Data Node DaemonAfter=network.target auditd.service[Service]Type=forkingExecStart=/usr/sbin/ndbdExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failure[Install]WantedBy=multi-user.target# 采用daemon-reload重新加载systemd’s manager配置sudo systemctl daemon-reload# 让我们刚创建的服务生效，使data node daemon可以开机执行sudo systemctl enable ndbd# 启动服务sudo systemctl start ndbd# 禁止服务sudo systemctl stop ndbd# 验证NDB Cluster Management service服务正在执行sudo systemctl status ndbd 2.3.5 配置并运行MySQL Server和Client 标准的MySQL server不支持 MySQL Cluster 引擎 NDB。这意味着我们需要安装含有定制的SQL服务器 MySQL Cluster软件。 192.168.50.129和192.168.50.128都作为MySQL Server node 进入包含MySQL Cluster组件的目录cd install 在安装MySQL server 前，需要安装两个依赖库（如果已经安装过可忽略） sudo apt updatesudo apt updatesudo apt install libaio1 libmecab2 安装解压在install目录的软件包中的一些MySQL Cluster依赖包 cd /install/sudo dpkg -i mysql-common_8.0.19-1ubuntu16.04_amd64.debsudo dpkg -i mysql-cluster-community-client-core_8.0.19-1ubuntu16.04_amd64.debsudo dpkg -i mysql-cluster-community-client_8.0.19-1ubuntu16.04_amd64.debsudo dpkg -i mysql-client_8.0.19-1ubuntu16.04_amd64.debsudo dpkg -i mysql-cluster-community-server-core_8.0.19-1ubuntu16.04_amd64.debsudo dpkg -i mysql-cluster-community-server_8.0.19-1ubuntu16.04_amd64.deb# 此处若是出现依赖问题，输入以下命令，再重新执行一遍上面语句 sudo apt-get -f install# 或者把依赖包删除 重装一遍sudo apt-get purge libaio1 sudo apt-get purge libmecab2 当安装mysql-cluster-community-server时，会出现配置提示，请求为mysql数据库root用户设置密码。在后面选项选择使用强安全密码 安装MySQL server:sudo dpkg -i mysql-server_8.0.19-1ubuntu16.04_amd64.deb 配置MySQL server # 打开MySQL Server 配置文件默认sudo vim /etc/mysql/my.cnf 可看到下列文本 往文本后追加(192.168.50.128填写的相同) [mysqld]# Options for mysqld process:ndbcluster # run NDB storage engine[mysql_cluster]# Options for NDB Cluster processes:ndb-connectstring=192.168.50.129 # location of management server 重启MySQL server，使上面的变化生效:sudo systemctl restart mysql MySQL默认开机自动启动。如果不能启动，下述命令可以修复:sudo systemctl enable mysql 2.3.6 验证MySQL Cluster安装 为了验证MySQL Cluster正确安装, 登陆Cluster Manager / SQL Server节点，为192.168.50.129/192.168.50.128。 打开MySQL客户端连接到root账号：mysql -u root -p 在MySQL客户端中, 运行下列命令: SHOW ENGINE NDB STATUS \\G，系统会显示NDB引擎的相关信息，表示成功连入MySQL Cluster number of ready_data_nodes= 2 如果一个数据节点挂了（本例中必须是那个没有安装MySQL Cluster管理器的节点），MySQL cluster还是可以继续工作 测试cluster的稳定性 shutting down非管理器节点（192.168.50.128），在整个过程中看到number_of_ready_data_nodes从2变为1。 再次开启服务，又由1变为2(这个变化过程有延迟，需要等待一会)。同理停止管理器节点上的ndbd服务。 在集群管理器控制台上查看集群信息，命令为：ndb_mgm。然后在集群管理器控制台输入SHOW，输出信息如下： 192.168.50.128的数据节点ndbd断开连接的情况 192.168.50.128的数据节点ndbd未断开连接的情况 192.168.50.128的mysql服务器启动 退出MySQL客户端，使用quit或按CTRL-D 管理控制台功能很多，有很多其他的管理命令来管理集群和数据, 包括创建在线备份. 更多信息参考官方official MySQL documentation 2.3.7 向MySQL集群插入数据 注意为了使用集群功能, 必须使用NDB数据库引擎。如果使用InnoDB (default)或其他引擎,将不能使用集群。 # 打开MySQL客户端连接到root账号mysql -u root -p# 首先, 创建数据库clustertest:CREATE DATABASE clustertest;# 其次转到新数据库:USE clustertest;# 再次，创建表test_table:# 需要显式规定ndbcluster引擎CREATE TABLE test_table (name VARCHAR(20), value VARCHAR(20)) ENGINE=ndbcluster;# 现在可以插入数据了:INSERT INTO test_table (name,value) VALUES('some_name','some_value');# 最后验证数据插入：SELECT * FROM test_table;# show databases 思考：在本例中，数据被插入到了哪个机器？ 我认为数据应该被插入了本地机器 在此处数据备份为2的话，则另一个数据节点有一份相同的备份 可以在my.cnf文件中设定默认数据存储引擎为ndbcluster，这样创建表时就不再规定引擎了。更多信息参考MySQL Reference Manual 2.4 结语 至此我们在Ubuntu 16.04 servers上安装和配置了a MySQL Cluster。需要注意的是这是一个很小的简化体系结构来说明配置过程，部署一个生产环境，还有许多其他的选项和特征需要去学习.。更多信息请参阅 MySQL Cluster documentation 2.5 验证可靠性 2.5.1 NDB存储引擎测试 在192.168.50.129的SQL节点创建数据库并且插入数据(一定要设置存储引擎为NDB)，在192.168.50.128的SQL节点可以查询到，两个SQL节点查询的数据时一致的，能够同步 use clustertest 2.5.2 单点故障测试 SQL节点发生单点故障 将SQL节点192.168.50.128上的MySQL服务停止 /etc/init.d/mysqld stop# sudo systemctl stop mysql ndb_mgm查看cluster状态 从SQL节点192.168.50.129上查看数据，正常 SQL节点的单点故障并没有引起数据查询的故障。对于应用来说，需要改变的就是将以前对故障节点的访问改为对非故障节点的访问 NDB(数据节点)单点故障 在这个测试环境中，数据节点也是两个，那么他们对数据的存储是互相镜像还是一份数据分成几块存储呢？这个答案关键在于配置文件中[NDBD DEFAULT]组中的NoOfReplicas参数，如果这个参数等于1，表示只有一份数据，但是分成N块分别存储在N个数据节点上，如果该值等于2，则表示数据被分成N/2,每块数据都有两个备份，这样即使有任意一个节点发生故障，只要它的备份节点正常，数据就可以正常查询 将NDB节点192.168.50.129上的ndbd服务停止 ps -ef | grep ndbdpkill -9 ndbd ndb_mgm查看cluster状态，NDB节点192.168.50.129上已经挂掉 从SQL节点192.168.50.128和SQL节点192.168.50.129上查看数据，正常 在此样例中，挂掉一个NDB节点不影响正常的数据查询，数据节点的冗余同样防止了NDB单点故障 如果该测试中，NoOfReplicas=1，如果有一个数据节点挂了，则无法正常访问完整数据 2.5.3 集群的关闭 关闭顺序：SQL节点-&gt;数据节点-&gt;管理节点 NDB节点和管理节点的关闭都可以在管理节点的管理程序中完成，也可以分节点关闭 关闭Cluster节点不会停止sql节点数据库服务 但在关闭整个MySQL Cluster环境(内部关闭：ndb_mgm&gt; shutdown)或者关闭某个SQL节点的时候，首先必须到SQL节点主机上来关闭SQL节点程序 2.6 思考问题 通过实验，你对一个分布式数据库系统有何理解？分布式数据库系统预计有何优越性？ 理解：分布在同一个网络；逻辑上属于同一个系统；物理上分布在不同的节点上 优越性： 适合分布式数据管理，能有效地提高系统性能，吞吐率和响应速度提高 分布式数据库系统可利用现有的设备和系统，省时、省力、投资少 提高了系统的可用性、可靠性和并行执行度，并允许存储数据副本 根据实际需要，可增减某一场地，系统具有可扩展性 分布式数据库系统资源和数据分布在物理上不同的场地上，为系统所有用户共享 你能设计一个方案验证集群系统在可靠性上优于集中式数据库系统吗？ 集中式数据库，单点，崩了就完了 同样是插入数据，你觉得MySQL Cluster和myCAT在实体完整性保持方面是否可能会有不同？为什么？ &gt; Entity Integrity ensures that there are no duplicate records within the table and that the field that identifies each record within the table is unique and never null. 实体完整性要求每个数据表都必须有主键，而作为主键的所有字段，其属性必须是独一及非空值 MySQL Cluster：auto-sharding，需要内存很大(被诟病) myCAT: 分表分库，即将一个大表水平分割为 N个小表，存储在后端MySQL服务器里或者其他数据库里。早期myCAT没有检测，不同数据库的完整性无法保证，现在未知。 3 问题与解决 无法连接虚拟设备sata0:1 解决：修改虚拟机 -&gt; 右键设置硬件 -&gt; CD/DVD(SATA) -&gt; 使用 ISO 映像文件 但我认为这不影响虚拟机的使用所以就没深入解决 提供此类问题temporary failure resolving cn.archive.ubuntu.com的解决思路 原因：无法解析该域名 试试nslookup www.baidu.com 如果发现服务器的DNS没有配，则 # 打开配置文件vi /etc/resolv.conf# 添加nameserver 114.114.114.114nameserver 8.8.8.8nameserver 223.5.5.5 报错：该虚拟机似乎正在使用中。如果该虚拟机未在使用，请按\"获取所有权(T)\"按钮获取。获取所有权失败。原因:VM异常关闭导致。 解决：进入VM虚拟机的存放目录，删除后缀为.lck的文件 VMware-以独占方式锁定此配置文件失败.另一个正在运行 上述的方法都没有成功，通过在Windows程序与功能-&gt;修复vmware解决 每次重启虚拟机后，/etc/resolv.conf文件就要重新配置，之前的都被抹去 # resolv.conf文件其实是一个Link文件# 在Ubuntu中有一个 resolvconf的服务，这个服务用来控制/etc/resolv.conf的内容# 一旦我们重启了系统或者该服务，那么/etc/resolv.conf文件中的内容将被还原为原来的内容sudo vi /etc/resolvconf/resolv.conf.d/base# [应用更改](https://www.zhoushangren.com/archives/779)sudo resolvconf -u ping: unknown host www.baidu.com的解决方法 # ping 网关auto ens33iface ens33 inet dhcp 4 实验总结 VMware挂起 相当于物理机中的休眠，会将内存中的数据全部存放到对应的休眠文件中，占用的空间为内存大小，并且会对虚拟机执行关机操作 休眠后的虚拟机不占任何CPU、内存 相对于关机，只多了一个和内存大小相同的休眠文件 VMware不像virtualbox可以从外部将虚拟机强行终止，VMware的虚拟机若是不正常关机，下一次启动会出现很多莫名其妙的问题。 sudo apt-get update总是出问题的时候，通过科学上网、修改dns服务器、更改镜像源等操作后未果，可以不要选择大晚上执行命令，太闹心，再也不做这种傻逼事，放一放，换个时间可能会顺利很多。输入该命令之前可添加sudo apt-get clean，若是文件被锁住，则ps -aux | grep apt*获取有关进程的PID，然后sudo kill PID。 update和upgrade的区别：update是更新软件列表，upgrade是更新软件。在执行upgrade之前要先update update: 同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引upgrade：升级已安装的所有软件包，升级之后的版本就是本地索引里的 apt和apt-get的区别 &gt; apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合 &gt; &gt; 用 apt 替换部分 apt-get 系列命令，但不是全部 5 参考资料 在VMware Workstation中安装Ubuntu Server 16.04.5图解教程 为VMware虚拟机内安装的Ubuntu 16.04设置静态IP地址 SSH远程连接安装在VMware的Ubuntu16.0.4 # 查看虚拟机是否能够ping外网# 不行，配置DNS服务器 `sudo vi /etc/resolv.conf`# 重启网络sudo /etc/init.d/networking restart# 检查当前的ssh开启情况# 如果有sshd，则ssh-server已经启动；若仅有agent，则尚未启动ps -e |grep ssh# 查看端口情况sudo netstat -plntu# 开启ssh服务/etc/init.d/ssh start# 重启sshsudo /etc/init.d/ssh restart# 当主机ssh连接虚拟机出现ssh: connect to host 192.168.50.129 port 22: Connection timed out# 解决1:测试虚拟机是否能访问外网 MySQL Cluster搭建与测试 MySQL Cluster技术详解","link":"/2020/03/25/MySQL-Cluster-set-up-configuration/"},{"title":"Number Theory","text":"质数 因子分解 欧拉降幂 RAS 拓展中国剩余定理 质数 素数间隔-Prime gap The first 60 prime gaps are: 1, 2, 2, 4, 2, 4, 2, 4, 6, 2, 6, 4, 2, 4, 6, 6, 2, 6, 4, 2, 6, 4, 6, 8, 4, 2, 4, 2, 4, 14, 4, 6, 2, 10, 2, 6, 6, 4, 6, 6, 2, 10, 2, 4, 2, 12, 12, 4, 2, 4, 6, 2, 10, 6, 6, 6, 2, 6, 4, 2 有无穷对素数，之间存在着一定的间隔。间隔从被证明为7000万以内，一直到如今的246。如果该常数改进到2，相当于证明孪生素数猜想 素数之间间隔可以有多远，The 80 known maximal prime gaps 素数定理-Prime Number Theorem 质数分布密度，数的总数π(x)近似于x/ln(x) π(2)=1，π(3.5)=2，π(10)=4 素数筛法 求\\(1\\)到\\(n\\)之间内的所有素数 方法 时间复杂度 \\(sqrt(n)\\)的判别 \\(O(n*sqrt(n))\\) 普通筛 / 埃氏筛法 \\(O(nloglogn)\\) 线性筛 / 欧拉筛法 \\(O(n)\\) 素数测试-Miller Rabin 哥德巴赫猜想：任何大于2的偶数都能够写成两个质数相加的形式 当题目给出的偶数达到\\(10^{18}\\)，此时的质数可能非常大，用上述的筛法可能会超时，用Miller Rabin快速判断一个\\(&lt;2^{63}\\)的数是不是素数 时间复杂度：\\(O(klog_2(n))\\)，\\(n\\)为检测的数值，\\(k\\)为自己设定的检测的次数 不确定算法，单次测试有不超过\\(\\frac{1}{4}\\)的概率会将一个合数误判为一个素数 依据 费马小定理： \\(若p是质数，则对于任意0&lt;a&lt;p，\\) \\(有a^{p−1}≡1(modp)\\) 二次探测定理： \\(若p是质数，且x^2≡1(modp)，\\) \\(那么x≡1 (modp)和x≡p−1(modp)中有一个成立\\) 算法过程 偶数、0、1、2直接判断 假设要测试的数为\\(n\\)，选取整数\\(r\\)和奇数\\(d\\)，满足\\(n-1=2^rd\\) 选取\\(a \\in (1,...,n-1)\\) 如果\\(a^d=1(modn)\\)或者\\(a^d=n-1(modn)\\)，即满足二次探测定理，则调回Step 3继续验证 对于\\(i=0,...,r-1\\)，验证\\(a^{2^id}\\)是否满足\\(a^{2^id}=n-1(modn)\\)，满足则跳回Step 3继续验证，不满足则\\(n\\)为合数 经过\\(k\\)次验证后，\\(n\\)可能是素数 伪码 Input #1: n &gt; 3, an odd integer to be tested for primalityInput #2: k, the number of rounds of testing to performOutput: “composite” if n is found to be composite, “probably prime” otherwisewrite n as 2^r·d + 1 with d odd (by factoring out powers of 2 from n − 1)WitnessLoop: repeat k times:pick a random integer a in the range [2, n − 2]x ← a^d mod nif x = 1 or x = n − 1 then continue WitnessLooprepeat r − 1 times: x ← x^2 mod n if x = n − 1 then continue WitnessLoopreturn “composite”return “probably prime” 模板 typedef unsigned long long ll;//typedef long long ll;//ll*ll可能会溢出，所以乘法化加法/* ************************************************** Miller_Rabin 算法进行素数测试* 速度快可以判断一个 &lt; 2^63 的数是不是素数***************************************************/#include&lt;time.h&gt;#include&lt;stdlib.h&gt;const int S = 8; //随机算法判定次数一般 8～10 就够了// 计算 ret = (a*b)%c a,b,c &lt; 2^63ll mult_mod(ll a,ll b,ll c){ a%=c; b%=c; ll ret=0; ll tmp=a; while(b){ if(b&amp;1){ ret+=tmp; if(ret&gt;c)ret-=c;//直接取模慢得多 } tmp&lt;&lt;=1; if(tmp&gt;c)tmp-=c; b&gt;&gt;=1; } return ret;}// 计算 ret = (a^n)%modll pow_mod(ll a,ll n,ll mod){ ll ret=1; ll tmp=a%mod; while(n){ if(n&amp;1)ret=mult_mod(ret,tmp,mod); tmp=mult_mod(tmp,tmp,mod); n&gt;&gt;=1; } return ret;}// 通过 a^(n-1)=1(modn)来判断 n 是不是素数// n - 1 = x * (2^t)// 中间使用二次判断// 是合数返回 true, 不一定是合数返回 falsebool check(ll a,ll n,ll x,ll t){ ll ret = pow_mod(a,x,n); ll last = ret; for(int i = 1;i &lt;= t;i++){ ret = mult_mod(ret,ret,n); if(ret == 1 &amp;&amp; last != 1 &amp;&amp; last != n-1)return true;//合数 last = ret; } if(ret != 1)return true; // 费马小定理 else return false;}//**************************************************// Miller_Rabin 算法// 是素数返回 true,(可能是伪素数)// 不是素数返回 false//**************************************************bool Miller_Rabin(ll n){ if( n &lt; 2)return false; if( n == 2)return true; if( (n&amp;1) == 0)return false;//偶数 ll x = n - 1; ll t = 0; while( (x&amp;1)==0 ){x &gt;&gt;= 1; t++;} srand(time(NULL));/* *************** */ for(int i = 0;i &lt; S;i++){ ll a = rand()%(n-1) + 1; if( check(a,n,x,t) ) return false; } return true;} 大数的质因子分解-Pollard Rho \\(O(n^{\\frac{1}{4}})\\)的期望时间复杂度内计算合数\\(n\\)的某个非平凡因子(平凡因子指\\(1\\)和\\(n\\)，非平凡因子指\\(x \\in [2,n-1]，n mod x=0\\)) 试除法：\\(n\\)的因数对称分布，遍历区间\\([1,\\sqrt N]\\)，时间复杂度为\\(O(\\sqrt N)\\) 不直接寻找因子，而是寻找因子的倍数，然后通过GCD找到因子本身 思路 对于\\(N⩾10^{18}\\)，使用随机算法-猜因数 组合随机采样-生日悖论：满足答案的组合比单个个体要多一些。假如一个班上有\\(k\\)个人，如果找到一个人的生日是x月x日，这个概率会相当低；如果想找两个生日相同，当\\(k=23\\)，两个人在同一天生日的概率至少有\\(50\\%\\)，\\(k=60\\)时，生日有重复的现象的概率\\(\\text{P}(k) ≈0.9999\\) 最大公约数一定是某个数的约数。通过选择适当的\\(k\\)使得\\(\\gcd(k,n)&gt;1\\)，则求得的\\(\\gcd(k,n)\\)是\\(n\\)的约数。则选取一组数\\(x_1,x_2,x_3,...x_n\\)，若有\\(gcd(|x_i-x_j|,n)&gt;1\\)，则称\\(gcd(|x_i-x_j|,n)\\)是\\(n\\)的一个因子 构造一个伪随机数序列，然后取相邻的两项来求gcd。Pollard设计了一个函数: \\(f(x)=(x^2+c)\\mod N\\) 其中c是一个随机的常数。选取\\(x_1\\)，令\\(x_2=f(x_1),x_3=f(x_2),...,x_i=f(x_{i-1})\\) Floyd判圈：在一定范围内，这个数列是随机的；但也有死循环的情况。龟兔赛跑：兔子比乌龟快一倍，同起点同时开始，当兔子“追上”乌龟时，兔子一定跑了刚好一圈。 brent判环(更高效) kuangbin的模板 //**************************************************// Miller_Rabin 算法// 是素数返回 true,(可能是伪素数)// 不是素数返回 false//**************************************************bool Miller_Rabin(ll n){ if( n &lt; 2)return false; if( n == 2)return true; if( (n&amp;1) == 0)return false;//偶数 ll x = n - 1; ll t = 0; while( (x&amp;1)==0 ){x &gt;&gt;= 1; t++;} srand(time(NULL));/* *************** */ for(int i = 0;i &lt; S;i++){ ll a = rand()%(n-1) + 1; if( check(a,n,x,t) ) return false; } return true;}//**********************************************// pollard_rho 算法进行质因素分解//*********************************************ll factor[100];//质因素分解结果（刚返回时时无序的）int tol;//质因素的个数，编号 0～tol-1ll gcd(ll a,ll b){ ll t; while(b){ t = a; a = b; b = t%b; } if(a &gt;= 0)return a; else return -a;}//找出一个因子ll pollard_rho(ll x,ll c){ ll i = 1, k = 2; srand(time(NULL)); ll x0 = rand()%(x-1) + 1; ll y = x0; while(1){ i++; x0 = (mult_mod(x0,x0,x) + c)%x;//不断调整x2 ll d = gcd(y - x0,x); if( d != 1 &amp;&amp; d != x)return d;//找到因子，返回 if(y == x0)return x;//判圈 出现循环，返回 if(i == k){y = x0; k += k;} }}// 对 n 进行素因子分解，存入 factor. k 设置为 107 左右即可// 如果n 本身就是素数，那么将 n 存放在 factor 便可结束并返回// 如果 n 不是素数，那么通过 pollard_rho()函数 找到 n 的一个因子 p(不一定是素因子)，递归 findFac(p)和 findFac(n/p)void findfac(ll n,int k){ if(n == 1)return;//递归出口 if(Miller_Rabin(n)) { factor[tol++] = n; return; } ll p = n; int c = k; //值变化，防止死循环 while( p &gt;= n) // 改变常数c，不断找因子，返回n说明没找到 p = pollard_rho(p,c--); findfac(p,k); findfac(n/p,k);} 洛谷 P4718【模板】Pollard-Rho算法 - TLE的原因 欧拉降幂 给三个正整数，\\(a,m,b\\)，需要求：\\(a^b mod m\\) \\(1\\le a \\le 10^9，1\\le b \\le 10^{20000000}，1\\le m \\le 10^8\\) 指数爆炸 欧拉定理：\\(a^{\\varphi(p)}≡1 \\ mod \\ p，a和p互质\\) 拓展欧拉降幂 \\(a^b\\equiv \\begin{cases} a^{b\\bmod\\varphi(p)},&amp;\\gcd(a,p)=1\\\\ a^b,&amp;\\gcd(a,p)\\ne1,b&lt;\\varphi(p)\\\\ a^{b\\bmod\\varphi(p)+\\varphi(p)},&amp;\\gcd(a,p)\\ne1,b\\ge\\varphi(p) \\end{cases} \\pmod p\\) 假设\\(k=\\frac{b}{\\varphi(p)},h=bmod\\varphi(p)\\)，则\\(a^b=a^{k*\\varphi(p)+h}=(a^{\\varphi(p)})^k*a^h=a^h(modp)\\) 欧拉降幂公式的证明 求单个数的欧拉函数 long long eular(long long n){ long long ans = n; for(int i = 2;i*i &lt;= n;i++){ if(n % i == 0){ ans -= ans/i; while(n % i == 0)n /= i; } } if(n &gt; 1)ans −= ans/n; return ans;} 拓展欧拉函数 以字符串形式读入大数，处理得到\\(bmod\\varphi(p)\\) 需要判断\\(b\\)和\\(\\varphi(p)\\)的大小，否则会出错 // char b[maxn]ll ans=0;c=eular(p);ll len = strlen(b);int flg=0;for(ll i = 0;i &lt; len; i++){ ans = (ans*10 + b[i]-'0'); if(ans&gt;=p){ flg=1; ans%=p; }}if(flg)ans+=p;// 快速幂计算 a是底数，ans是指数，p是模数qPow(a,ans,p); 洛谷 P5091 模板题 欧拉函数常用性质和公式 \\(对于质数p，\\varphi(p)=p-1\\) \\(\\sum_{d|n}\\varphi(d)=n\\quad，包括1和n本身\\) \\(\\sum_{gcd(d,n)==1}d=\\varphi(n)*n/2\\) \\(\\sum_{i=1}^{n-1}gcd(i,n)=\\sum_{d|n}d\\varphi(n|d)\\) \\(若p为质数，n=p^k,\\varphi(n)=p^k-p^{k-1}\\) \\(积性性质：若m,n互质，\\varphi(m*n)=\\varphi(m)*\\varphi(n)\\) RSA 算法流程 公钥密码算法 \\(随机选择两个不相等的质数p和q\\) \\(计算p和q的乘积n\\) \\(计算n的欧拉函数φ(n)=(p-1)(q-1)\\) \\(随机选择一个整数e，满足1&lt;e&lt;φ(n)，且e与φ(n)互质\\) \\(求出整数d，使得ed ≡ 1 (mod φ(n))\\) \\((n,e)为公钥，d为私钥\\) \\(加密：明文消息m，满足0&lt;m&lt;n，密文c=m^e mod n\\) \\(解密：接受到密文消息为c，解密明文消息m=c^d mod n\\) 知识点 逆元(欧拉定理)+快速幂 若(a*x)%mod=1，则x是正整数a在模mod下的逆元 方法 限定 时间复杂度 线性打表法 只要求mod是质数 O(n) 费马小定理 mod是质数且与a互质，快速幂优化 O(log(n)) 欧拉定理 只要求a与mod互质，需要欧拉函数与快速幂 O(sqrt(n)+log(n)) 拓展欧几里德 只要求a与mod互质 O(log(n)) 拓展中国剩余定理 中国剩余定理 韩信点兵，三三一排少1人，五五一排少1人，七七一排少1个人 \\(对于一组同余方程\\) \\(x≡a_1 (mod n_1)\\) \\(x≡a_2 (mod n_2)\\) \\(...\\) \\(x≡a_k (mod n_k)\\) \\(模数n_1,n_2...n_k两两互质，求最小的x\\) \\(计算N=n_1×n_2×⋯×n_k\\) \\(对于i=1,2,…,k，\\) \\(计算y_i=\\frac{N}{n_i}=n_1n_2...n_{i-1}n_{i+1}...n_k\\) \\(对于i=1,2,…,k，计算z_i=y_i^{-1}(modn_i)，\\) \\(即计算y_i在模n_i下的逆元\\) \\(x=\\sum_{i=1}^ka_iy_iz_i，\\) \\(最后计算x=x(modN)得到结果\\) 模数两两不互质 思路 \\(通过先解出前两个方程的解，如将前两个方程\\) \\(x≡a_1 (mod n_1)，x≡a_2 (mod n_2)化为x≡A(mod N)\\) \\(将此方程和x≡a_3 (mod n_3)\\) \\(继续联立求解，直到最后一个方程解完为止\\) 洛谷 P4777 模板题 \\(x≡a_1 (mod n_1)\\) \\(x≡a_2 (mod n_2)\\) \\(可化为 x=a_1+k_1*n_1 ①; x=a_2+k_2*n_2;\\) \\(消x，可得a_1+k_1*n_1=a_2+k_2*n_2\\) \\(移项得到k_1*n_1+(-k_2)*n_2=a_2-a_1\\) \\(令d=a_2-a_1, x=k_1, y=-k_2;\\) \\(上式化为 x*n_1+y*n_2=d ③\\) \\(令g=gcd(n_1,n_2),用拓展欧几里得解线性方程\\) \\((此处求解x_1，y_1)，x_1*n_1+y_1*n_2=g\\) \\(③式可化为 x_1*(d/g)*n_1+y_1*(d/g)*n_2 = g*(d/g)\\) \\(即x=x_1*(d/g)=k_1 ; y=y_1*(d/g)=-k_2;\\) \\(即k_1=x_1*(d/g); k_2=-y_1*(d/g)\\) \\(一组通解为 k_1=k_1+(n_2/g)*T; k_2=k_2-(n_1/g)*T\\) \\(要求使所求得的解最小且为正整数，\\) \\(则可以根据 k_1的通解形式求得(消掉T的影响)\\) \\(k_1=(k_1 mod (n_2/g)+(n_2/g)) mod (n_2/g) ②，\\) \\(即k_1=((x_1*(d/g)) mod (n_2/g)+(n_2/g)) mod (n_2/g)\\) \\(将求出的k_1带入①，可得x的解，\\) \\(作为下一次的A，N为lcm(n1,n2)，\\) \\(即A为合并后的a，N为合并后的n\\) typedef long long ll;ll exgcd(ll a,ll b,ll &amp;x,ll &amp;y){ if(a==0&amp;&amp;b==0)return -1; if(b==0){x=1;y=0;return a;} ll d=exgcd(b,a%b,y,x); y-=a/b*x; return d;}ll excrt(){ ll a1=b[0],n1=a[0],a2,n2,d,x,y,gcd;//余数 b[] 除数 a[] // 返回的是最小非负整数解，有些题目需要特判 //若当余数为0的时候 题目要求求正整数 所以0不算在内，应该加上下面的注释，即余数等于除数，同理后面的板子 //if(a1==0)a1=a[0] for(int i=1;i&lt;n;i++){ a2=b[i];n2=a[i]; d=a2-a1; gcd=exgcd(n1,n2,x,y); if(d%gcd)return -1; x=((x*d/gcd)%(n2/gcd)+(n2/gcd))%(n2/gcd); a1=x*n1+a1; n1=n1*n2/gcd; } return a1;} 定理&amp;猜想&amp;公式 费马大定理： \\(当整数n &gt;2时，\\) \\(关于x, y, z的方程 x^n + y^n = z^n 没有正整数解\\) 实数域不可拆分多项式： \\(一次多项式和二次多项式(b^2&lt;4ac)\\) 艾森斯坦因判别法：有理数域不可约，即一定要整数解 勾股数 任意大于2的整数都可以找出另外两个数构成勾股数 本原勾股数 四色猜想 康威常数 日期转化成星期 蔡勒公式 基姆拉尔森计算公式 斯特林公式 - 阶乘","link":"/2020/04/12/Number-Theory/"},{"title":"软件安全概述","text":"三大软件安全问题 有什么安全问题，安全问题产生的原因 二进制方面 内存相关问题 有明确的机制 例子：缓冲区溢出，空指针，格式化字符串 逻辑错误问题 多种多样 Web方面 典型安全问题 XSS，SQL注入 非典型安全问题：很多 主要是一些代码的逻辑错误，每个漏洞都可能有不同的原理 如何去发现问题 (安全漏洞) -&gt; 漏洞挖掘技术 白盒分析 分析软件的源代码去寻找问题 方法 手工代码分析 -&gt; 软件测试技术 / 代码review。但是软件的源代码通常比较庞大，手工分析起来很费劲 自动化代码分析 -&gt; 典型的技术：符号执行 黑盒分析 因为白盒分析数据量大，需投入很多人工，人们寻求简单方法，和白盒分析对立的黑盒发展 原理：完全不管软件的内部机理 / 不看源码，把需要分析的软件当做一个黑盒子，看不见 / 根本不去看内部 方法：分析表面现象 软件：通过输入和输出去猜测内部机制 黑盒分析法，Fuzzing技术(模糊测试) 如果有人利用这这些安全问题，如何防御 补丁 由于软件复杂性，要发现问题及时修补 方法 通过漏洞数据库来披露和管理各种漏洞，厂家有义务定期发布软件补丁或者更新 软件用户应该及时升级软件 第三方人员，如果发现了安全问题，应该通报给厂家，而不是在漏洞修补以前，利用漏洞搞破坏，或者不负责任的披露漏洞 防御机制 寻找记录攻击的痕迹，然后分析这些数据 数据的来源分为了主机层面和网络层面 攻击者可能会做哪些方面的伪装，常用的伪装技术有哪些，如何去对抗伪装 方法：加壳脱壳技术 / Rootkit技术 研究第一大方面：缓冲区溢出和XSS 代表了二进制软件和脚本软件（包括绝大多数Web软件都是脚本软件开发的）两大技术方向 缓冲区溢出虽然比XSS底层，但是更难。XSS虽然比较上层，但是相对比较容易理解 计算机科学的特点就是，越底层的东西，越难 开发操作系统比开发app难多了 二进制软件 计算机的底层，是CPU直接执行在内存中的机器指令 C和C++这类编程语言开发的软件，通过编译链接过程，把程序变成CPU可以直接执行的二进制指令 这类软件的一个特点也是不可避免的一点：需要直接操作内存(指针) 内存是所有在运行态的软件及其数据保存的地方 内存分为细小的单元，每个单元有一个唯一的地址 二进制软件安全问题的根源 所有要访问数据，必须知道数据的地址，要保存新的数据，就必须分配内存，获得可用的地址 地址也是数，如果不小心计算错误，就会访问到不该访问的数据，造成数据的泄露或者破坏。 二进制程序的编程，有很大的难度的原因 二进制文件晦涩难懂 CPU只能执行二进制指令(是基于物理上的电路)，所以不可能设计得机制太复杂 脚本软件 在C和C++发展成熟以后，就有人去研究如何降低编程的难度，能否避免程序员编程时直接操作内存，把需要操作内存的地方，都封装起来，屏蔽在编程语言的内部 -&gt; 发明了脚本语言 概念：用C和C++这样的二进制程序开一个软件来执行一种新的程序，就是用软件来模拟CPU工作 由于软件的可定制性比CPU就高多了，可以想定义什么指令就定义什么指令 对象与封装：把所有需要操作内存的东西，全部封闭在执行器内部，只给程序员接口，不给程序员操作内存的机会。比如把字符串封装为string对象。只能调用string.len()这样的方法来操作这个对象。这样就避免了由于编程不慎造成的内存相关问题，也降低了编程难度 如python、java、js、web浏览器这样的脚本程序的执行器都是二进制程序。 解决了内存相关问题，有引出了其他的问题 用户输入问题。比如XSS出现的原因如下：web程序存在一种高交互性。web是互联网时代的软件的基本框架，所以会有用户提交数据。为了网页动态的需求，开发了网页的前端脚本，比如js，直接把脚本嵌入到网页中。浏览器只要发现了script标签，就去当做脚本来执行，把网页按照程序员的定制，变的丰富多彩，变得富于变化。但是，恰恰另外一种需求，就是UGC(User Generated Conten 用户生成内容)软件，也就是网页的内容来自于用户提交的内容，比如BBS、博客、微博，电商视频网站的用户评论，都会涉及到用户提交的内容在页面上呈现。当用户提交的内容里含有脚本，如果直接将用户提交的内容放在页面上，那么用户提交的内容中的脚本会不会被浏览器解析执行呢？那么一个用户提交了一个脚本就可以在这个页面的所有用户主机上执行呢？用户能提交程序执行了，怎么才能不保证这个程序不是恶意的呢？前端脚本，除了渲染页面元素这样的功能，还有获得用户的输入跳转页面到其他地址等等丰富的功能。 实验 编写一个简单的html文件 要求只要有一个表单，用户就可以在表单中输入数据，向服务器提交。 &lt;html&gt;&lt;body&gt;&lt;form method=\"post\"&gt; &lt;input type=\"text\"&gt; &lt;button&gt;提交&lt;/button&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 保存为index.html文件，用浏览器打开显示如下 搭建一个web服务器 如果这个html是放在web服务器上，用户输入了数据，点击提交，浏览器就会把编辑框中的数据封装为一个POST请求，发现服务器。服务器会把这个数据发给后端脚本来处理。 通过定义form的属性来指明需要哪个脚本文件来处理 比如PHP程序，他有一个POST超级变量，当用户提交了数据以后，对应的php脚本的post变量就是用户提交的数据 假设服务器现在把用户提交的数据放在user_input.html的body标签中。然后保存在服务器文件的根目录中。当有网站的用户访问 http://xxxx.com/user_input.html 的时候，就会看到刚才那个表单用户提交的内容。当然实际的情况是这两个用户可能不是同一个用户，于是A用户提交的内容B用户就访问到了。 当服务器脚本是原封不动的把用户输入的数据写到html里时，如果用户提交的数据中包括&lt;script&gt;标签，就会被执行。比如alert函数，弹出一个消息框，&lt;script&gt;alert('xss attack')&lt;/script&gt;；比如给window.location.href赋值，能让用户莫名其妙的跳转到另外一个网站 最简单的实验环境 在vscode中，安装一个php插件，然后编写一个简单的php脚本，调试运行这个脚本 F5 vscode会自动选择脚本运行的方式，把用户的表单输入写入到html文件 通过浏览器访问这个文件html文件，这就是一个最简单的xss运行环境了。 实际的XSS漏洞可能很复杂，比如还会有数据库、登录等。另外，编程语言也不限于php，java、python也可以 问题 当编写的代码中出现中文，在网页上显示乱码 编码问题，head标签里通过meta指定","link":"/2020/06/09/Software-Security/"},{"title":"Windows下git clone慢的尝试解决方法","text":"重启大法?! 重启网络，重启机器 科学上网 STILL SLOW ERROR: PRC fail git使用太多内存 git使用太多内存，需要先git gc 源代码过于庞大 http方式不行，可以用ssh的方式(首先要进行git ssh的配置) 需要修改git的http.postBuffer，加大git传输字节，仅对http形式有效 bash% 查看当前的配置git config -l% 加大httpbuffergit config --global http.postBuffer 524288000git config --global http.sslVerify false 修改host文件 通过查询ip地址 github.global.ssl.fastly.net github.com assets-cdn.github.com 位于C:\\Windows\\System32\\drivers\\etc目录下的hosts文件 按如下格式，在文件末尾写入 151.101.185.194 global-ssl.fastly.net140.82.113.3 github.com 刷新系统dns缓存 # 可在windows的cmd下ipconfig /flushdns ip经常会变，如发现速度又下降了，及时去更换ip git设置和取消代理 vpn的情况下 开全局代理的情况下，利用代理进行下载，对https有效，ssh无效 bashgit config --global http.proxy http://127.0.0.1:自己的端口号git config --global https.proxy https://127.0.0.1:自己的端口号# 可以在计算机的设置-&gt;代理查看# 取消方式git config --global --unset http.proxygit config --global --unset https.proxy# 查看目前所有的配置git config --global list 使用全局代理，clone国内仓库慢，改进：只对github进行代理，对国内的仓库不影响 # 先取消全局代理，通过上面的取消方法git config --global http.https://github.com.proxy https://127.0.0.1:自己的端口号git config --global https.https://github.com.proxy https://127.0.0.1:自己的端口号# 取消git config --global --unset http.https://github.com.proxygit config --global --unset https.https://github.com.proxy 关于git其他问题 “fatal: HttpRequestException encountered.” Error with GitHub/Bitbucket Repositories due to dropping TLS-1.0 support 参考资料 git设置和取消代理 谜之问题 可能是：短时间过多请求api造成的 解决： hexo\\themes\\next\\scripts\\events\\index.js 将作者修改的部分做注释","link":"/2020/03/21/Windows-git-clone-slow/"},{"title":"阿里云服务器(centos7系统) 使用nginx+uwsgi 部署python+flask项目","text":"Web服务器的搭建 阿里云ECS(centos7) + python flask + Nginx uwsgi、wsgi和nginx的区别和关系 CentOS7 python2升级到python3的那些坑 Centos7安装Python3的方法 Linux/UNIX 上安装 MySQL 选择MySQL5.7版本 8.0版本一直报错 CentOS7安装MySql8不能启动的问题 unable-to-access-mysql-after-it-automatically-generated-a-temporary-password mysql -uroot -p : 123456 mysql 修改 root 密码 ALTER USER 'root'@'localhost' IDENTIFIED BY 'test4321'; &gt; ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement https://blog.csdn.net/vv19910825/article/details/82979563 &gt; ERROR 1819 (HY000): Your password does not satisfy the current policy https://blog.csdn.net/hello_world_qwp/article/details/79551789 在本地端使用浏览器打开该云实例的公网地址:端口 nginx + uwsgi ip+端口号访问 Method 1 - 访问需ip + 端口号访问 web应用是由Flask内置的web服务托管 systemctl stop nginxkill uwsgi的所有进程systemctl stop iptablessystemctl stop firewalld# vi app.pyapp.run(host=&quot;0.0.0.0&quot;,port=5000)# app.run一定要设成 0.0.0.0 才可以访问# 以http://121.199.46.37:5000/ 访问 ip+端口号 Method 2 - uwsgi - 访问无需端口号，直接以阿里云服务器公网访问 pip install uwsgi uwsgi官方文档 run.py文件修改成app.run() 在项目中新建文件config.ini，uwsgi的配置/Sfim/src/config.ini，编写如下配置配置如下 [uwsgi]# uwsgi 启动时所使用的地址与端口socket = 127.0.0.1:5000# 外网访问端口，如果直接用uWSGI外网，这里由于使用了Nginx，故注释掉http= :80# 指向网站目录chdir = /root/test/# python 启动程序文件wsgi-file = app.py# python 程序内用以启动的 application 变量名# app 是 app.py 程序文件内的一个变量，这个变量的类型是 Flask的 application 类callable = app# 处理器数processes = 4# 线程数threads = 2#状态检测地址stats = 127.0.0.1:9191#daemonize=/var/log/uwsgi.log 启动：uwsgi --ini config.ini 使用uwsgi之后，修改app.py -&gt; app.run() 一定要保证代码风格是严格按照官网的 即app=Flask(name)要放在if __name__ = \"__main__\"外面 if __name__ = \"__main__\"里面只能放app.run() 不然会报错 Exception: Install 'email_validator' for email validation support.unable to load app 0 (mountpoint='') (callable not found or import error)--- no python application found, check your startup logs for errors --- 解决方法1 解决方法2 uwsgi运行相关应用时要加上-d参数使其在后台运行，否则断开ssh连接后uwsgi就停止运行了，-d后要加上项目的uwsgi.log文件，没有新建一个即可。例 -d ~/uwsgi.log Method 3 -nginx - 访问无需端口号，直接以阿里云服务器公网访问 先关闭uwsgi /etc/nginx/nginx.conf / 日志/var/log/nginx/error.log #只用nginx代理的配置server { listen 80; server_name 47.106.218.225; # 阿里云公网ip location / { proxy_pass http://127.0.0.1:5000; # 本机:启动端口（此处端口与项目端口一致） proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } python app.pynohup python app.py &gt;&gt; app.out &amp; 将运行日志输出到app.out文件nohup python run.py &gt;&gt; run.out &amp; # nohup 加在一个命令的最前面，表示不挂断的运行命令# &amp; 加在一个命令的最后面，表示这个命令放在后台执行# ps 和 jobs# 区别在于 jobs 只能查看当前终端后台执行的任务，换了终端就看不见了# ps命令适用于查看瞬时进程的动态，可以看到别的终端的任务# a: 显示所有程序 u: 以用户为主的格式来显示 x: 显示所有程序，不以终端机来区分# fg命令 将后台中的命令调至前台继续运行# Ctrl + z 命令 将一个正在前台执行的命令放到后台，并且处于暂停状态# bg命令 将一个在后台暂停的命令，变成在后台继续执行tail -f app.outtailf app.out Method 4 - nginx + uwsgi - 访问无需端口号，直接以阿里云服务器公网访问 &gt; config.ini#http = :80&gt; /etc/nginx/nginx.confserver { #ssl_protocols TLSv1.2; #server_tokens off; listen 80 default_server; #listen [::]:80 default_server; server_name 121.199.46.37; # 阿里云公网ip #root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { #proxy_pass http://127.0.0.1:5000; # 本机:启动端口(此处端口与项目端口一致) #proxy_set_header Host $host; #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; include uwsgi_params; uwsgi_pass 127.0.0.1:5000; uwsgi_param UWSGI_PYHOME /usr/bin/python; # python位置 uwsgi_param UWSGI_CHDIR /root/test; # 项目根目录 uwsgi_param UWSGI_SCRIPT app:app; }# 跑起来systemctl start nginxnginx -s reloadservice nginx restart # 重启nginx服务service nginx start # 启动服务service nginx stop # 停止服务 运行uwsgi服务（通过执行启动脚本运行项目）uwsgi --ini config.ini （启动脚本存放位置）# 后台运行uwsgi --ini config.ini --daemonize uwsgi.out 错误提示 [error] 2168#0: *19 connect() failed (111: Connection refused) while connecting to upstream 参考资料 &gt; config.ini[uwsgi]socket=127.0.0.1:8080plugins = pythonwsgi-file=test.pymaster=trueprocesses=4threads=2callable=appstats=127.0.0.1:9191&gt; nginx.confserver { listen 80; server_name 111.230.140.182; charset utf-8; client_max_body_size 75M; location / { include uwsgi_params; uwsgi_pass 127.0.0.1:8080; #uwsgi_param UWSGI_PYTHON /usr/bin/python; //注释掉 #uwsgi_param UWSGI_CHDIR /home/ubuntu/project/test; //注释掉 #uwsgi_param UWSGI_SCRIPT test:app ; //注释掉 }} 注意点： 不同的web application要更换不同的端口，否则会出错，即使停掉了所有服务只启动一个服务也是如此 nginx+uwsgi+flask的参考资料 Name Explanation Flask 一个轻量级的Python Web框架 Nginx 一个非常稳定的Web服务器 uwsgi 一个全站式的托管服务，它实现了应用服务器（支持多种编程语言）、代理、进程管理器、监视器 使用Nginx服务器托管Flask应用的安装、配置过程 Nginx是一个提供静态文件访问的web服务，然而，它不能直接执行托管Python应用程序，而uWSGI解决了这个问题？？？ 可以看看理论部分-使用Flask+uwsgi+Nginx部署Flask正式环境 直接使用python run.py运行服务的方式只适合本地开发 线上运行时要保证更高的性能和稳定性，需要使用uwsgi进行部署 使用Nginx有如下一些优点： 安全：不管什么请求都要经过代理服务器，避免了外部程序直接攻击web服务器 负载均衡：根据请求情况和服务器负载情况，将请求分配给不同的web服务器，保证服务器性能 提高web服务器的IO性能：对于一些静态文件，可以直接由反向代理处理，不经过web服务器 只看了概念解释-新手的Flask+uwsgi+Nginx+Ubuntu部署过程 一篇就弄懂WSGI、uwsgi和uWSGI的区别 备用资料 最新阿里云申请免费SSL证书实现网站HTTPS化（图文教程一） 通过在阿里云服务器ECS(系统为centos7)上搭建Web服务器，能够实现不仅仅是在本地，而是在互联网的访问我们的网站。使用uWSGI和Nginx部署flask项目， 其中uWSGI一个全站式的托管服务，它实现了应用服务器(支持多种编程语言)、代理、进程管理器、监视器，帮助实现WSGI协议、Http协议等，使得开发者不再需要关注网络通信的底层实现，而花更多的时间开发上层应用。 WSGI(Web Server Gateway Interface)服务器网关接口是Python应用程序或框架和Web服务器之间的一种接口，已经被广泛接受。只要遵照这些协议，WSGI应用(Application)都可以在任何服务器(Server)上运行。通过利用uWSGI可以使我们的web应用得到更强的并发能力。 通过Nginx，一个非常稳定的Web服务器和反向代理服务器，能够进一步提高并发能力和访问效率。Nginx还有如下优点：安全，不管什么请求都要经过代理服务器，避免了外部程序直接攻击web服务器；负载均衡，根据请求情况和服务器负载情况，将请求分配给不同的web服务器，保证服务器性能；提高web服务器的IO性能，对于一些静态文件，可以直接由反向代理处理和缓存，不经过web服务器。 用户和本项目搭建的应用程序中的交互流程为：Nginx接受来自客户端的Http请求发送给uWSGI，uWSGI处理请求并将关键信息传递给web框架flask或者web应用等，应用返回Response经由uWSGI发送给Nginx，Nginx再发送给客户端。 解决问题的实际感受：了解阿里云云服务器ECS，发现一台暴露在网络的服务器经常受到威胁和攻击，从买了他们的产品开始，每天都会有警告邮件，要按照阿里云官方的解决方法修补漏洞和加固，深入了解了Web服务器的部署，学习到了Nginx和uWSGI的知识 代码细节 sqlalchemy的用法 flask蓝图 编写index.html界面 index.html出现的位置home.py Windows跑代码 验证邮箱的时候，服务没有开启 www.sfim.tools 改为 192.168.0.101:8080 models里面是和数据库有关的 windows 安装 mysql 8.0.19 安装教程 mysql front 报错","link":"/2020/06/21/aliyun-sfim/"},{"title":"软件安全中的二进制安全","text":"二进制安全是整个软件安全中核心的内容 二进制软件 核心：二进制是软件的最基本形态 所有的基础软件都是以二进制软件的形式存在 二进制软件：操作系统、浏览器、数据库、中间件、各种脚本软件的解释执行器、很多大型游戏 二进制软件的基本特征：是CPU可以直接运行的机器指令 CPU能够运行的机器指令都是二进制的，包括了很多非ASCII的不可打印字符 二进制程序无法跨平台：不同平台的二进制软件是不同的，Intel架构的cpu的二进制无法在ARM架构上运行，反之也是 二进制形式的软件无法跨操作系统运行：二进制程序还需要操作系统的支持 直接使用二进制或者十六进制进行编程，人进行数据阅读比较困难，效率非常低下 -&gt; 编程的时候不直接处理二进制，直接使用文本来编程 文本代码CPU无法执行，需要编译和链接 程序员编写出来的文本形式的代码 -&gt; 源代码 首先发明的源代码是汇编形式的，是使用的和机器指令一一对应的汇编语言，是一种直接最简单的操作指令级别的翻译过程 汇编的编程还不是很方便，后来发明了C语言等高级语言，高级语言不止C语言一种，但是C比较成功，又发明了C++ 编译后生成的机器可运行的代码 -&gt; 目标代码 研究二进制安全，首先需要了解的就是二进制软件和源代码，之后是脚本语言的关系 软件安全研究的核心问题 看表面不够，深入内部细节，需要了解的软件的具体原理，到代码级别 已经发现的软件安全典型的问题：栈溢出、堆溢出、格式化字符串漏洞、空指针、整形溢出等等 软件安全研究的两个核心问题 安全问题（也叫脆弱性，通常叫漏洞）的存在性问题 - 漏洞挖掘 这个安全问题的可利用性问题，安全漏洞具体有什么危害，如果达到这个危害如何防止 - 漏洞利用 漏洞挖掘 - 安全问题的存在性问题 安全问题的脆弱性，通常叫漏洞 由于软件安全的漏洞都是具体的，都是由软件内部的代码的编程不慎所引起的 &gt; 所以漏洞挖掘方法就是分析代码 分析二进制（安全人员捕获一个攻击程序后拿不到源代码，源代码在发起攻击的人 / 黑客手上） 在了解二进制机器指令的基本原理后，通过一些辅助的工具来解读 通过逆向工程的一些技术，把二进制软件解构、翻译，然后就能理解其实现的原理 漏洞挖掘技术现在是攻防双方都在使用：软件的开发人员也在采用黑客发明的漏洞挖掘技术来挖自己的漏洞，以争取在软件发布前把安全问题尽量发现和修补 反汇编 反汇编以及在汇编代码上的一些解构，比如获得函数列表、获得每个函数的调用关系、获得函数内部的控制流程图 变量名、函数名、注释、一些数据类型是源代码层面方便程序员编程的，对于二进制软件来讲，名称信息没有用处，机器指令内部全部是使用“数据和代码的存储地址” 反汇编工具：基本 &gt; dumpbin &amp; objdump，高级 &gt; IDA-pro 所有的调试器也都有反汇编功能 调试器 调试器比反汇编器要高级，因为反汇编器只能在程序没有运行起来的时候去观察它，而调试器可以在程序运行起来以后，随时中断程序的运行并观察 运行时的信息要更丰富，比如运行时候可以看到用户输入的数据、外部读入的数据、这些数据的具体处理过程、某个变量在运行时的赋值情况等，这些信息都是静态的反汇编所没有的。但信息丰富则需要分析和处理的数据量是非常大的 调试器还有一个反汇编器没有的功能：能捕获程序执行的异常 异常信息：因为二进制软件的安全问题，通常会引起程序运行时的内部数据结构被破坏，比如各种溢出，其实是覆盖了正常的数据。内部数据结构被破坏以后，程序在后续执行时，可能访问这些不正常的数据，进而引起运行时错误 大多数运行时错误，最后都变成内存访问的异常 &gt; 虚拟内存管理方面的知识 漏洞寻找 有了调试器和反汇编器，就有了观察和了解程序内部原理的工具，这些基础工具就像医院用的心电图、X光和CT一样，是获得内部基础数据的工具。但是只有这些工具，有时候还是不能发现具体问题，我们得了解具体漏洞产生的原因，比如溢出，为什么溢出是严重的安全问题 寻找漏洞最直接的思路，是一行行看代码 &gt; 可行性 &amp;&amp; 巨大的麻烦(软件是一个非常复杂和庞大的事物，比如Windows，有上万名开发人员，持续开发了20年，发布了无数个版本。如果一行行看代码，还不是源代码，是二进制反汇编代码，则需要和开发人员同等数量的人员和时间，这往往是达不到的) 所以漏洞的挖掘，极少情况下会直接人工分析源代码，安全研究人员们，更希望借助自动化的工具 两大类自动化工具：模糊测试工具 &amp; 程序分析工具 模糊测试(Fuzzing) 认为软件很复杂，干脆不要去看内部了，把软件当做一个黑盒子，只看它的外部表现，给它各种各样的输入，看它在处理过程中会不会出现异常。如果有异常就说明软件在设计的过程中，没有考虑到用户会输入这样的数据，和软件的预期不符合，则存在漏洞。程序异常通常会引起程序的崩溃，用调试器来捕获异常，能实现自动化 通过研究漏洞的原理，漏洞是畸形数据引起的，比如输入了一个超长的字符串，比程序员内部预留的长，则发生溢出。所以通过输入畸形数据去尝试触发崩溃的方法，理论上也是可行的 通过随机，构造畸形数据。随机并不是每次都能构造出正好合适的畸形数据，但是随即构造大量数据以后很有可能有那么一两次成功 软件虽然复杂，但是运行速度很快，可以不停的自动运行目标软件，让软件来处理这些随机构造的可能是畸形的数据，然后运行的时候启动调试器来捕获可能得异常，虽然不是每次都能触发异常 模糊测试工具 深入软件的内部原理的，分析它的每一行代码 代表的技术：危险函数定位和符号执行等 危险函数定位的思路是，既然strcpy等能引起缓冲区溢出，那么就把全部的strcpy找出来看一看。随着研究的深入，人们发现，不是所有的漏洞都是危险函数引起的。内存操作的方法各种各样，千奇百怪，而且不是所有的危险函数都会引起安全问题。比如调用之前进行了长度判断 &gt; 所以这种方法效果很差 符号执行：分析方法，逐步复杂 漏洞利用 - 安全问题的可利用性问题 安全漏洞具体有什么危害 / 安全缺陷的危害，如果达到这个危害，如何防止 编写exp（漏洞利用程序）也是软件安全研究人员的基本功 exp一般分为攻击数据部分 + 攻击成功后的控制部分，前一部分比如一个超级长的字符串，用来溢出缓冲区；后一部分，就是shellcode shellcode很多时候可以通用，但是攻击数据部分，每个漏洞都不一样。这部分的学习，比较有效的办法就是去阅读和使用别人写好的exp。kali Metasploit exploit-db上有很多这样的程序，有一些安全研究人员的个人博客上也有很多。所以大家就去找一两个公开了exp的具体的漏洞，搭建漏洞环境，解读学习exp &gt; 漏洞复现 别人已经挖掘发现的漏洞 一些软件厂家，比如微软会定期升级自己的系统，打补丁。在打补丁升级系统的时候，就会同时给出安全公告说修补了那些问题 统一的数据库CVE：但是并不是每个软件厂家都有能力或者意愿去维护一个安全漏洞。有一些第三方的组织就来收集各种漏洞，并形成了一个统一的数据库，比如CVE CVE给每个漏洞都编写，说明漏洞影响的软件及其版本，危害程度等等详细信息 少量的漏洞还会给出PoC，也就是概念验证程序。早期的漏洞很多都有PoC，因为那个时候，很多软件厂家不重视漏洞修补工作。漏洞的发现人员，或者安全厂商放出PoC也能逼迫软件厂商去修补 现在，软件漏洞的披露已经很规范了。国家也重视，所有美国和我们有国家安全漏洞数据库，美国有NVD，我们国家的CNVD和CNNVD。这些都是大家去找已经公开的漏洞的地方 漏洞复现 如果拿到了一个漏洞的详细公告和PoC，如何去复现这个漏洞：安装一个有漏洞存在的软件版本 虚拟机：这个过程中，通常在虚拟机里安装配置。因为漏洞需要的环境可能和我们的工作主机的环境冲突很大，而且漏洞环境复现过程中，可能会破坏系统。如果我们要复现很多漏洞，不在虚拟机中进行，会把自己的工作环境弄得很乱 模拟器：模拟器和虚拟机相似又不同，他们都是在内部构造了一个“虚拟的机器”。这个虚拟的机器可以和真实的机器一样安装和运行操作系统以及各种软件。但是虚拟机，还是借助的物理CPU的虚拟化功能，而模拟器是使用软件来“实现”了一个CPU及其附属的设备 - 虚拟机的host系统和guest系统，只能是同一架构的。比如物理主机是intel架构，那么host和guest都这能是Intel 0x86架构的系统，比如Windows和Linux x86。但是模拟器就可以跨架构，host是Windows x86，guest是arm架构的安卓系统。 - 模拟器的典型代表：QEMU - 如果要研究安卓系统、路由器等MIPS架构的系统，就需要模拟器 - 模拟器通常也有调试、单步运行等功能，除了用于漏洞复现，也可用于漏洞挖掘。比如要挖掘一个路由器的漏洞，不能直接对着物理路由器Fuzzing，因为就是触发了异常，也无法捕获。所以通常是把固件提取出来，在模拟器中运行 软件攻防 黑客如果通过攻击，进入到了一个目标系统。除了要考虑窃取信息、加密硬盘（勒索软件）、破坏数据等攻击之外，还需要考虑：第一是不留痕迹，第二是不能被杀毒软件和主机中的一些防御系统识别 早期，安全研究人员也在想办法对抗漏洞攻击和计算机病毒（计算机病毒其实就是一个可以自我复制的漏洞利用程序）。他们想到的办法就是杀毒软件 - 杀毒软件的基本原理是把已经发现的病毒等各种恶意程序的特征值记录在数据库中，每当系统中有新的文件时就计算一下这个文件的特征值，然后和数据库中的特征值进行比较，如果匹配上了，说明这是一个恶意程序 - 特征值通常是hash值。因为恶意软件很多，不可能把整个恶意软件都作为特性，占用空间也不方便分发特征值（分发特征值就是病毒升级）。但是如果源数据稍微变化一下，hash值就变化了。比如病毒修改自己的一个无意义的常量数据，功能不变，杀毒软件就无法查杀了。所以后来有发明了动态的基于行为的检测。 - rootkit技术：恶意软件需要隐蔽自己，比如文件、进程、通讯的端口都需要隐藏起来 - rootkit技术很多是基于API hook。通过挂钩API，篡改了操作系统的行为，当防御软件在列举目录中文件时，根本就获取不到攻击程序的文件 防御软件和攻击软件就是一个技术博弈，此消彼长的过程，产生了非常多很有意思的技术： - 比如攻击软件为了防止被发现，根本就不产生文件。可执行程序首先是一个文件，在系统上创建进程运行。后来出现了根本不产生文件，也不修改其他文件，寄生在其他可执行程序进程中、直接从网络加载到内存就能运行的恶意程序 - 外挂：外挂程序也是通过修改正常程序的软件行为，比如直接篡改内存中的数据，或者挂钩其函数，达到修改软件行为的目的。开发和防御外挂软件的技术与软件攻防技术相似，都是需要使用逆向工程工具和调试器等、都需要大量的数据分析工作","link":"/2020/06/13/binary-safe/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new \"My New Post\" More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment","link":"/2020/03/15/hello-world/"},{"title":"hexo+github搭建博客","text":"Hexo是一个基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题 github：https://github.com/hexojs/hexo 官网：http://hexo.io hexo 一些命令 &amp; 用法 一般下载的主题的位置位于hexo/themes，切换主题的时候需要修改hexo/_config.yml中的theme 一般生成的文章的位置位于hexo/source/_posts 所有的命令都在git bash下进行，一些hexo的命令 # hexo generate 生成静态文件 hexo g# hexo server 启动服务，在本地预览hexo s # hexo deploy 部署网站# 上传到github，无需通过git add和git push，但需要配置hexo d# 新建文章hexo new &quot;name&quot;# 新建页面hexo new page &quot;pageName&quot; 插入图片 # hexo/_config.yml post_asset_folder: true# hexo n 生成md博文时，/source/_posts文件夹内除了md文件还有一个同名的文件夹，不再赘述# 在hexo目录下，安装上传本地图片的插件，我装了会出错npm install hexo-asset-image --save# 卸载npm uninstall hexo-asset-image The symbols count is undefined and reading time is NaN:aN Github 部署到github上，通过hexo直接更新github仓库 如果要通过hexo d直接上传，需要配置 ssh key 修改hexo/_config.yml中有关deploy的部分 deploy: type: git repository: git@github.com:purplezi/purplezi.github.io.git branch: master 安装插件npm install hexo-deployer-git --save 其他主题 Fluid，基于 Hexo 的一款 Material Design 风格的主题 github：https://github.com/fluid-dev/hexo-theme-fluid 官网：https://hexo.fluid-dev.com/docs 配置指南：https://hexo.fluid-dev.com/docs https://github.com/blinkfox/hexo-theme-matery https://github.com/litten/hexo-theme-yilia 推荐用yilia-plus https://www.zhihu.com/question/24422335?utm_source=qq&amp;utm_medium=social&amp;utm_oi=868617446326681600 http://ppoffice.github.io/hexo-theme-icarus dark mode change: https://blog.sbx0.cn/2020/04/07/icarus-3-night-mode/ 更换主题后出现文章的图片加载不出，找不到原因 解决方法：对每篇文章进行微修改，就可以马上加载出来了 如果是配置gitee的Gitee Pages，不是Pro，则需要手动到Gitee Pages上更新 参考资料 hexo+Github超深度优化 在hexo中加入图片、音频、视频","link":"/2020/03/21/hexo-github/"},{"title":"IP地址","text":"localhost、127.0.0.1、0.0.0.0、本机IP的区别 - https://zhuanlan.zhihu.com/p/72988255 - https://www.cnblogs.com/operationhome/p/8681475.html - https://www.jianshu.com/p/ad7cd1d5be45","link":"/2020/07/20/ipaddress/"},{"title":"XSS攻击","text":"使用python内置的库开发一个基本的http服务器端 测试代码 使用python原生的cgi和http.server两个库运行的一个简单的http服务器程序 因为没有使用第三方库，所有不需要使用pip安装依赖 运行比较简单 公共网关接口（Common Gateway Interface，CGI）是Web 服务器运行时外部程序的规范，按 CGI 编写的程序可以扩展服务器功能 讲解代码 # -*- coding: utf-8 -*-import sysimport cgifrom http.server import HTTPServer, BaseHTTPRequestHandlerclass MyHTTPRequestHandler(BaseHTTPRequestHandler): field_name = 'a' form_html = \\ ''' &lt;html&gt; &lt;body&gt; &lt;form method='post' enctype='multipart/form-data'&gt; &lt;input type='text' name='%s'&gt; &lt;input type='submit'&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; ''' % field_name def do_GET(self): self.send_response(200) self.send_header(\"Content-type\", \"text/html\") self.end_headers() try: file = open(\".\"+self.path, \"rb\") except FileNotFoundError as e: print(e) self.wfile.write(self.form_html.encode()) else: content = file.read() self.wfile.write(content) def do_POST(self): form_data = cgi.FieldStorage( fp=self.rfile, headers=self.headers, environ={ 'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': self.headers['Content-Type'], }) fields = form_data.keys() if self.field_name in fields: input_data = form_data[self.field_name].value file = open(\".\"+self.path, \"wb\") file.write(input_data.encode()) self.send_response(200) self.send_header(\"Content-type\", \"text/html\") self.end_headers() self.wfile.write(b\"&lt;html&gt;&lt;body&gt;OK&lt;/body&gt;&lt;/html&gt;\")class MyHTTPServer(HTTPServer): def __init__(self, host, port): print(\"run app server by python!\") HTTPServer.__init__(self, (host, port), MyHTTPRequestHandler)if '__main__' == __name__: server_ip = \"0.0.0.0\" server_port = 8080 if len(sys.argv) == 2: server_port = int(sys.argv[1]) if len(sys.argv) == 3: server_ip = sys.argv[1] server_port = int(sys.argv[2]) print(\"App server is running on http://%s:%s \" % (server_ip, server_port)) server = MyHTTPServer(server_ip, server_port) server.serve_forever() 运行代码 使用python httpserver.py或者py httpserver.py 使用vscode调试代码，在同目录下会自动生成一个.vscode的目录，目录下生成launch.json文件，配置如下 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Python: 当前文件\", \"type\": \"python\", \"request\": \"launch\", \"program\": \"${file}\", \"console\": \"integratedTerminal\" } ]} 在浏览器的访问网址为127.0.0.1:8080/a.html 主要的父类与子类 http methods http请求下的多种methods 通常使用得最多的，是 GET 和 POST 直接在浏览器中输入链接，浏览器拿到地址以后，默认是采用 GET 方式向服务器发送请求，GET 方式最常见。 表单使用的 post 方法提交数据 &lt;form method='post' enctype='multipart/form-data'&gt; 通常来说，从服务器获取数据，使用 get 方法，向服务器提交数据，使用 post 方法 其他的方法，在现在的web应用程序中，用到的很少 MyHTTPServer类 MyHTTPServer类，是继承自原生的HTTPServer，重写 init 函数，增加了打印输出语言 然后直接调用父类 HTTPServer 的 init 函数传递了服务器运行需要的地址、端口等参数，我们的监听地址和端口是 0.0.0.0:8080 class MyHTTPServer(HTTPServer): def __init__(self, host, port): print(\"run app server by python!\") HTTPServer.__init__(self, (host, port), MyHTTPRequestHandler) MyHTTPRequestHandler MyHTTPRequestHandler 类，这个是 HTTPServer 的回调，用来处理到达的请求，也就是 0.0.0.0:8080 上有任何的 HTTP 请求到达时，都会调用 MyHTTPRequestHandler来处理 MyHTTPRequestHandler 直接继承自 BaseHTTPRequestHandler 重写了父类的 do_GET和do_POST两个方法 这个HTTP请求的处理类是整个代码的主体，也是出问题的地方 在 python 的 BaseHTTPRequestHandler 类中 ，do_XXX函数，就是处理对应的客户端请求的函数。代码指定了 MyHTTPRequestHandler 来处理 http 请求，那么当用 GET 方法请求，就会调用 do_GET，POST 方法请求，就会调用 do_POST函数 浏览器所发送的数据包里包括请求类型， 在 http 的 headers里，会说明方法。 这是python最基本的http 服务器的方式 其他处理 通常，一个静态的http服务器，这里的路径就是 http 服务器根目录下的文件，动态服务器可能是文件和参数，或者是对应其他服务器后台的处理过程 self.path 是这个请求的路径 例如 http://127.0.0.1:8080/a.html 。其中 http://127.0.0.1:8080是协议服务器地址和端口。/a.html就是路径 例如 http://127.0.0.1:8080/a.php?p1=x 。指定由 a.php 来处理这个请求，参数是 p1=x 。问号后面是参数，可以有多个 一般来说，如果读的文件不存在，应该返回404 self.send_response(200) 按照协议应该是404 则这里的处理为 如果指定的文件不存在，还是返回200，表示请求路径是正确的，可以处理，然后返回一个默认的页面。这个页面是 form_html的变量，在FileNotFoundError异常处理过程中写回 self.wfile 和 self.rfile 对应 http 响应和请求的 body 部分 GET处理完成以后，浏览器就拿到了 200 状态的 \"Content-type\" 为 \"text/html\" 的 form_html 在浏览器刷新是重复上一次的POST请求，所以会提示是否要重新提交表单 调试运行 在 def do_GET 下断点，刷新浏览器，代码就会断点命中中断。 结合浏览器，抓包看看 http 请求和响应的数据格式 （用抓包器或者浏览器的调试模式观察） 浏览器调试模式 打开浏览器的调试模式(chrome &gt; 菜单 &gt; 更多工具 &gt; 开发者工具) 在sources这个标签下看到服务器向浏览器返回的数据，即 form_html 变量 这一段 html 浏览器渲染出来，就是那个带一个编辑框的表单- 表单指定了使用post方式向服务器提交数据 在network tab里可以看到完整的请求响应过程 完整的网络数据，其中 header 里就说了 GET 或者 POST 、返回的状态码200等等 在表单中填入数据，点提交按钮，然后服务器的 do_POST 函数被调用。通过 cgi.FieldStorage解析了客户端提交的请求，原始的请求的头部在self.headers。body部分在self.rfile。解析完成以后放到 form_data变量里，其中 form_data['field_name'].value 是在编辑框中填入的数据 form_data = cgi.FieldStorage( fp=self.rfile, headers=self.headers, environ={ 'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': self.headers['Content-Type'], }) 使用场景 通常，一个服务器会根据业务逻辑处理用户提交的数据，比如用户发表的商品评论，比如在线教学系统中填入的作业一般会写入数据库。但是这些数据，在某些情况下又会被显示出来，比如其他用户查看别人的商品评论的时候，比如老师查看学生的作业时。 为了模拟这个过程，简化了一下，没有用户系统，也没有数据库，直接写入了 path 对应的文件。 处理用户提交，写入文件 fields = form_data.keys()if self.field_name in fields: input_data = form_data[self.field_name].value file = open(\".\"+self.path, \"wb\") file.write(input_data.encode()) fields = form_data.keys()是获取表单中的键值对，因此使用.value得到输入的值：这里获得是对应的是form中input的name &lt;input type='text' name='%s'&gt; 表单以变量名变量值的方式组织，input的name相当于变量名，填入的数据就是变量值 python的cgi.FieldStorage将form组织为python的dict数据类型，所以可以通过 form_data['field_name'].value 获得所填入的数据 如果写入成功，就返回一个 200 状态的 OK self.send_response(200) self.send_header(\"Content-type\", \"text/html\") self.end_headers() self.wfile.write(b\"&lt;html&gt;&lt;body&gt;OK&lt;/body&gt;&lt;/html&gt;\") ``` ## 漏洞- 如果向网页中填入了 123 ，那么123被写入了a.html文件。执行完成后，同目录下会多一个a.html，内容为123。然后下次再访问 http://127.0.0.1:8080/a.html 时，在浏览器地址栏里回车。由于这个时候a.html已经存在了，所以是运行的部分是 ```py else: content = file.read() self.wfile.write(content) 会直接把文件内容会写给浏览器 这里是在简化模拟用户提交数据 &gt; 存入数据 &gt; 其他用户获取这个数据的过程 XSS漏洞 再访问一个不存在的页面，比如b.html，又会出现那个默认的form。这时输入&lt;html&gt;&lt;body&gt;&lt;script&gt;alert('XSS')&lt;/script&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;，然后在访问b.html的时候，整个页面被载入 script 在浏览器上执行，也就是用户提交的数据被执行了 重新开一个页面，在c.html中填入&lt;html&gt;&lt;body&gt;&lt;script&gt;window.location.href='http://by.cuc.edu.cn'&lt;/script&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;。下次再访问c.html的时候。页面跳转了。window.location.href='http://by.cuc.edu.cn' 这段脚本的功能是实现了跳转 理论上，任何的js都是可以被执行的。js可以实现非常丰富的功能。比如可以骗取用户扫码、支付，实际到黑客的账户。如果是没有基本防御措施的网站，这段会被放进服务器数据库里，然后别人提交了数据就自动跳转到这个网站。比如有一个商品A，用户在评论里输入了一段js代码。如果服务器不做处理直接保存。后面的用户访问商品A、看评论，前一个用户输入的代码就会在其他用户的页面上执行。 Furthermore 如果大家在浏览器中访问 http://127.0.0.1:8080/httpserver.py ，则在sources中显示全部完整的源代码。由于服务器没有做任何过滤，只要是存在的文件，就发送给客户端 现在黑客可以知道我整个后台的逻辑了。 如果还有一些配置文件，比如数据库地址和访问口令等。那就更严重了 更严重的是，黑客甚至可以注入后端代码。由于我们是回写到文件，可以构造一个http post请求，把httpserver.py文件改写了。但是构造这个请求用浏览器就不行了，需要采用curl等更基础的工具裸写post请求发送给服务器的 在调试工具的 elements tab，由于后台只处理名为a的表单项写入文件，所以我们需要把input的把 name=\"%s\" 改为 name=\"a\" 再提交。改为以后，同时在提交框中输入‘hahaha’提交。此时httpserver.py，它变为'hahaha'，只是注入一个hahaha 服务器就挂了，再也跑不起来了。 所以，这是一个及其简单，但是漏洞百出的web服务器。这就是不做任何过滤，直接写入数据的危害。 参考资料 http methods","link":"/2020/06/11/xss-attack/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Hbase","slug":"Hbase","link":"/tags/Hbase/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"MkDocs","slug":"MkDocs","link":"/tags/MkDocs/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"Travis","slug":"Travis","link":"/tags/Travis/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Cluster","slug":"Cluster","link":"/tags/Cluster/"},{"name":"数论","slug":"数论","link":"/tags/%E6%95%B0%E8%AE%BA/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"uwsgi","slug":"uwsgi","link":"/tags/uwsgi/"},{"name":"web server","slug":"web-server","link":"/tags/web-server/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"xss","slug":"xss","link":"/tags/xss/"},{"name":"security","slug":"security","link":"/tags/security/"}],"categories":[{"name":"DataBase","slug":"DataBase","link":"/categories/DataBase/"},{"name":"Blogs","slug":"Blogs","link":"/categories/Blogs/"},{"name":"ACM","slug":"ACM","link":"/categories/ACM/"},{"name":"Security","slug":"Security","link":"/categories/Security/"},{"name":"git","slug":"git","link":"/categories/git/"}]}